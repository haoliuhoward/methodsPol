[{"authors":["howardhliu"],"categories":null,"content":"Howard Liu is Assistant Professor of Political Science at The University of South Carolina.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"e8f41c7135bbc11b3d576b66bca8ca13","permalink":"/authors/howardhliu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/howardhliu/","section":"authors","summary":"Howard Liu is Assistant Professor of Political Science at The University of South Carolina.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":null,"content":" Logistics Preparation Assignments Weekly check-in Problem sets Coding challenges (extra credit) Final project Grade disputes Extensions on assignments (excluding final project) Logistics Preparation You will succeed in this class if you (1) attend lecture, (2) attend section, and (3) do the problem sets.\nAssignments Weekly check-in Every week, while you finish working through the content, I want to hear about what you learned and what questions you still have. To do this, you will fill out a short-response on Canvas that simply asks you what (if anything) you: 1) found interesting or compelling from the content so far; 2) found confusing or muddly from the content so far.\nProblem sets To practice coding in R you will complete problem sets throughout the quarter. Feel free to work together on the problem sets but you must turn in your own answers to Canvas. You cannot work in groups of more than three people.\nCoding challenges (extra credit) From time to time, I will hold in-lecture üî•üî• coding challenges üî•üî• that the whole class will participate in. Students will have the opportunity to earn extra credit during these challenges.\nFinal project You will code ‚Äì using all of the tools from the course ‚Äì an original data analysis of a mystery dataset. The format will be similar to the homeworks: a take-home RMD file with instructions and empty code chunks for you to fill in. Plus places to write your own analysis.\nGrade disputes If you believe that you received the wrong grade on an assignment or exam:\nsend an email specifying exactly which questions you believe were graded incorrectly, and provide specific justification for why your answer is the correct one. We will then regrade your entire assignment. Your grade may go up, down, or stay the same I will only accept grade appeals up to three days after the posting of a grade Extensions on assignments (excluding final project) You can turn in the problem set/weekly check-in one day late, no questions asked, though you will lose a full letter-grade. Beyond that I will not accept late assignments without a doctor‚Äôs note, so don‚Äôt ask! The final project will not be accepted late.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"Logistics Preparation Assignments Weekly check-in Problem sets Coding challenges (extra credit) Final project Grade disputes Extensions on assignments (excluding final project) Logistics Preparation You will succeed in this class if you (1) attend lecture, (2) attend section, and (3) do the problem sets.\nAssignments Weekly check-in Every week, while you finish working through the content, I want to hear about what you learned and what questions you still have. To do this, you will fill out a short-response on Canvas that simply asks you what (if anything) you: 1) found interesting or compelling from the content so far; 2) found confusing or muddly from the content so far.","tags":null,"title":"Description of assignments","type":"docs"},{"authors":null,"categories":null,"content":" If I assign readings, you really should read them.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"40fcd2da3bf2dc718a2fe044c31cdc56","permalink":"/reading/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/","section":"reading","summary":"If I assign readings, you really should read them.","tags":null,"title":"Description of readings","type":"docs"},{"authors":null,"categories":null,"content":" Online help Helpers and Templates Guides Online help I have been programming in R for years and still find myself Googling how to do basic things that I‚Äôve forgotten about. Other times, I encounter new coding problems where I can‚Äôt quite come up with a good solution.\nFortunately there are tons of online resources to help you. The most important is StackOverflow (a Q\u0026amp;A site with hundreds of thousands of answers to all sorts of programming questions). I will point to others as the semester advances.\nHelpers and Templates RMarkdown Cheatsheet An overview of Markdown and RMarkdown conventions. RStudio Cheatsheets Other quick guides, including a more comprehensive RMarkdown reference and a information about using RStudio‚Äôs IDE, and some of the main tools in R. Guides R Style Guide. Write readable code. Jenny Bryan‚Äôs Stat 545. Notes and tutorials for a Data Analysis course taught by Jennifer Bryan at the University of British Columbia. Lots of useful material. knitr demos Documentation and examples for knitr by its author, Yihui Xie. There is also a knitr book covering the same ground in more detail. Rmarkdown documentation from the makers of RStudio. Lots of good examples. Plain Person‚Äôs Guide The git repository for this project. Karl Broman‚Äôs Tutorials and Guides Accurate and concise guides to many of the tools and topics described here, including getting started with reproducible research, using git and GitHub, and working with knitr. Makefiles for OCR and converting Shapefiles. Some further examples of Makefiles in the data-analysis pipeline, by Lincoln Mullen ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"5912f73d0134416d302ef6bce989b8bf","permalink":"/reference/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reference/","section":"reference","summary":"Online help Helpers and Templates Guides Online help I have been programming in R for years and still find myself Googling how to do basic things that I‚Äôve forgotten about. Other times, I encounter new coding problems where I can‚Äôt quite come up with a good solution.\nFortunately there are tons of online resources to help you. The most important is StackOverflow (a Q\u0026amp;A site with hundreds of thousands of answers to all sorts of programming questions).","tags":null,"title":"General help","type":"docs"},{"authors":null,"categories":null,"content":" Install R Install RStudio Extra installation help (Mac): steps Extra installation help (Windows): video Install packages Install {juanr} (and other packages from Github) You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard‚ÄîR handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.\nInstall R First you need to install R itself (the engine).\nIf you have a WINDOWS, click here: Download R 4.2.1 for Windows\nIf you have a MAC, click here: Download R 4.2.1 for macOS\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nIf you use macOS, download and install XQuartz. You do not need to do this on Windows.\nInstall RStudio Next, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won‚Äôt ever have to interact with R directly.\nIf you have a WINDOWS, click here: Download RStudio for Windows If you have a MAC, click here: Download RStudio for macOS Double click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program. Double click on RStudio to run it (check your applications folder or start menu).\nExtra installation help (Mac): steps Here‚Äôs a different helpful walkthrough for Mac\nExtra installation help (Windows): video Here‚Äôs a different, helpful walkthrough for Windows\nInstall packages Most R packages are easy to install with RStudio. Select the packages panel, click on ‚ÄúInstall,‚Äù type the name of the package you want to install, and press enter. R will download the package from the web, so make sure you are connected to wifi when you do it.\nA less tedious way to do this is via the console or in your script (just make sure to delete afterwards!), by running the following code:\ninstall.packages(\u0026quot;name_of_package\u0026quot;) Install {juanr} (and other packages from Github) Some packages, like {juanr} cannot be installed using install.packages() because they are hosted on Github. To install {juanr}, you will first need to install {remotes} and then use install_github(), like so:\ninstall.packages(\u0026quot;remotes\u0026quot;) remotes::install_github(\u0026quot;hail2thief/juanr\u0026quot;) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"32d2aa5db9c906dd4dae32456ff00876","permalink":"/reference/install/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reference/install/","section":"reference","summary":"Install R Install RStudio Extra installation help (Mac): steps Extra installation help (Windows): video Install packages Install {juanr} (and other packages from Github) You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard‚ÄîR handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.","tags":null,"title":"Installing R, RStudio, packages","type":"docs"},{"authors":null,"categories":null,"content":" What kind of file is it? Where is it? How to do this better Most of the data in this course will come from packages. I do this so we have more time to focus on the stuff that matters. But most of the data in the world is not in a package. How can I read this kind of data into R?\nThere‚Äôs ways to do this in Rstudio through drop-down menus but I call that the ‚Äúno learning‚Äù approach.\nTo read data into R you need to know two things:\nWhat kind of file is it? What is its extension? Where is it? What is its file path? What kind of file is it? There are many different types of files out there. You can tell what type of file a dataset is by looking at its extension - the bit in the file name that comes after the period. Some common file types/extensions are .csv, .dta, .xlsx, etc.\nR has different functions you can use to import different types of files. For a .csv file you would use read_csv() or read.csv(). For a .dta you would use read_dta() from the {haven} package. For an .xlsx file you would use read_excel() from {readxl}. If you‚Äôre not sure, google what function to use for a particular data file.\nWhere is it? This part is tricky for people who don‚Äôt have a lot of experience working with computers. But, in short: every file that is on your computer has a ‚Äúpath‚Äù or ‚Äúaddress‚Äù that uniquely identifies it on your computer. This address changes with your file‚Äôs location; if you moved the file for whatever reason, the file path would change. You need the file path in order to tell R where to look at your data.\nHow to find it? Operating systems are always changing so in general the best thign is to google how to find a file‚Äôs filepath and then remember it. But the following seems to have worked on Mac for a long time now:\nfind the file in your Finder right-click and select ‚Äúget info‚Äù at the top left, under ‚ÄúGeneral‚Äù, you‚Äôll see the file path next to ‚ÄúWhere:‚Äù right-click that path and select ‚Äúcopy as Pathname‚Äù And on Windows you can do this.\nCode to import data into R might look like this:\ndf = read_csv(\u0026quot;/Users/juan/Dropbox/teaching/co2-data/owid-co2-data.csv\u0026quot;) How to do this better For working on longer term projects, it is more convenient to use relative file paths in conjunction with something like R projects (.Rproj) + the {here} library.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4793b3304002e159fc98333d15f3fea5","permalink":"/reference/import-data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reference/import-data/","section":"reference","summary":"What kind of file is it? Where is it? How to do this better Most of the data in this course will come from packages. I do this so we have more time to focus on the stuff that matters. But most of the data in the world is not in a package. How can I read this kind of data into R?\nThere‚Äôs ways to do this in Rstudio through drop-down menus but I call that the ‚Äúno learning‚Äù approach.","tags":null,"title":"Importing data into R","type":"docs"},{"authors":null,"categories":null,"content":" R style conventions Main style things to pay attention to for this class Spacing Long lines Pipes (%\u0026gt;%) and ggplot layers (+) Comments R style conventions R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\nmpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty\u0026gt;10, class==\u0026quot;compact\u0026quot;) filter(mpg,cty\u0026gt;10,class==\u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) filter ( mpg,cty\u0026gt;10, class==\u0026quot;compact\u0026quot; ) But you‚Äôll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there‚Äôs an unofficial style guide for writing R code. It‚Äôs fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)‚Äîyou should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ‚åò + i (on macOS), and R will reformat the code for you. It‚Äôs not always perfect, but it‚Äôs really helpful for getting indentation right without having to manually hit space a billion times.\nMain style things to pay attention to for this class Spacing See the ‚ÄúSpacing‚Äù section in the tidyverse style guide.\nPut spaces after commas (like in regular English):\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter(mpg , cty \u0026gt; 10) filter(mpg ,cty \u0026gt; 10) filter(mpg,cty \u0026gt; 10) Put spaces around operators like +, -, \u0026gt;, =, etc.:\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter(mpg, cty\u0026gt;10) filter(mpg, cty\u0026gt; 10) filter(mpg, cty \u0026gt;10) Don‚Äôt put spaces around parentheses that are parts of functions:\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter (mpg, cty \u0026gt; 10) filter ( mpg, cty \u0026gt; 10) filter( mpg, cty \u0026gt; 10 ) Long lines See the ‚ÄúLong lines‚Äù section in the tidyverse style guide.\nIt‚Äôs generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters. Instead of counting characters by hand (ew), in RStudio go to ‚ÄúTools‚Äù \u0026gt; ‚ÄúGlobal Options‚Äù \u0026gt; ‚ÄúCode‚Äù \u0026gt; ‚ÄúDisplay‚Äù and check the box for ‚ÄúShow margin‚Äù. You should now see a really thin line indicating 80 characters. Again, you can go beyond this‚Äîthat‚Äôs fine. It‚Äôs just good practice to avoid going too far past it.\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n# Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Bad filter(mpg, cty \u0026gt; 10, class %in% c(\u0026quot;compact\u0026quot;, \u0026quot;pickup\u0026quot;, \u0026quot;midsize\u0026quot;, \u0026quot;subcompact\u0026quot;, \u0026quot;suv\u0026quot;, \u0026quot;2seater\u0026quot;, \u0026quot;minivan\u0026quot;)) # Good filter(mpg, cty \u0026gt; 10, class %in% c(\u0026quot;compact\u0026quot;, \u0026quot;pickup\u0026quot;, \u0026quot;midsize\u0026quot;, \u0026quot;subcompact\u0026quot;, \u0026quot;suv\u0026quot;, \u0026quot;2seater\u0026quot;, \u0026quot;minivan\u0026quot;)) Pipes (%\u0026gt;%) and ggplot layers (+) Put each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n# Good ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Bad ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Super bad ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Super bad and won\u0026#39;t even work ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() Put each step in a dplyr pipeline on separate lines, with the %\u0026gt;% at the end of the line, indented with two spaces:\n# Good mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Bad mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Super bad mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Super bad and won\u0026#39;t even work mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) Comments See the ‚ÄúComments‚Äù section in the tidyverse style guide.\nComments should start with a comment symbol and a single space: #\n# Good #Bad #Bad If the comment is really short (and won‚Äôt cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\nmpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% # Only rows where cty is 10 + group_by(class) %\u0026gt;% # Divide into class groups summarize(avg_hwy = mean(hwy)) # Find the average hwy in each group You can add extra spaces to get inline comments to align, if you want:\nmpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% # Only rows where cty is 10 + group_by(class) %\u0026gt;% # Divide into class groups summarize(avg_hwy = mean(hwy)) # Find the average hwy in each group If the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to ‚ÄúCode‚Äù \u0026gt; ‚ÄúReflow comment‚Äù\n# Good # Happy families are all alike; every unhappy family is unhappy in its own way. # Everything was in confusion in the Oblonskys‚Äô house. The wife had discovered # that the husband was carrying on an intrigue with a French girl, who had been # a governess in their family, and she had announced to her husband that she # could not go on living in the same house with him. This position of affairs # had now lasted three days, and not only the husband and wife themselves, but # all the members of their family and household, were painfully conscious of it. # Bad # Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys‚Äô house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it. Though, if you‚Äôre dealing with comments that are that long, consider putting the text in R Markdown instead and having it be actual prose.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b2f9d1fa35d3bc06f09aadba1712d23a","permalink":"/reference/style/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reference/style/","section":"reference","summary":"R style conventions Main style things to pay attention to for this class Spacing Long lines Pipes (%\u0026gt;%) and ggplot layers (+) Comments R style conventions R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\nmpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty\u0026gt;10, class==\u0026quot;compact\u0026quot;) filter(mpg,cty\u0026gt;10,class==\u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) filter ( mpg,cty\u0026gt;10, class==\u0026quot;compact\u0026quot; ) But you‚Äôll notice that only a few of those iterations (the first three) are easily readable.","tags":null,"title":"Writing R code neatly","type":"docs"},{"authors":null,"categories":null,"content":" Intro Pulling the table Cleaning up the data and making the plot Intro library(tidyverse) library(rvest) library(janitor) There‚Äôs a lot of information on the internet. Sometimes this information is nicely formatted, which means we can scrape it from the internet fairly easily.\nTake a look at the table on this page of Simpsons guest star appearances: https://en.wikipedia.org/wiki/List_of_The_Simpsons_guest_stars\nWe‚Äôre gonna pull this table from the internet into R. You‚Äôll need the rvest and janitor packages. Install if you don‚Äôt have them.\nPulling the table First step is to pull down the whole Wikipedia page. To do so, use the read_html function, putting the URL of the site we want to scrape inside of it (in quotation marks!). Assign this to an object named content.\ndf = read_html(\u0026quot;https://en.wikipedia.org/wiki/List_of_The_Simpsons_guest_stars\u0026quot;) Now we have the whole page. We just want that table. Run the html_table function on content and store that in an object called table. Add fill = TRUE within the function otherwise you‚Äôll get an error.\ntable = html_table(df, fill = TRUE) Notice up top in your environment that you have an object called table that is a list with 13 elements. That means we have 13 tables from that page. But we only want the one with guest stars! Which one is it?\nWe need to look at the elements in that list to figure out which of the 13 tables is ours. To look at a specific element in a list, we can use the pluck() function, like so:\ntable %\u0026gt;% pluck(1) ## # A tibble: 1 √ó 1 ## X1 ## \u0026lt;chr\u0026gt; ## 1 Seasons: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ‚Ä¢ Movie ‚Ä¢ 19 20 21 22 2‚Ä¶ The first element in our list is not what we want; what about the second?\ntable %\u0026gt;% pluck(2) ## # A tibble: 676 √ó 6 ## Season `Guest star` `Role(s)` No. `Prod. code` `Episode title` ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 21 Matt Groening Himself 442‚Äì‚Ä¶ LABF13 \u0026quot;\\\u0026quot;Homer the W‚Ä¶ ## 2 21 Kevin Michael Richardson Security ‚Ä¶ 442‚Äì‚Ä¶ LABF13 \u0026quot;\\\u0026quot;Homer the W‚Ä¶ ## 3 21 Seth Rogen Lyle McCa‚Ä¶ 442‚Äì‚Ä¶ LABF13 \u0026quot;\\\u0026quot;Homer the W‚Ä¶ ## 4 21 Marcia Wallace Edna Krab‚Ä¶ 443‚Äì‚Ä¶ LABF15 \u0026quot;\\\u0026quot;Bart Gets a‚Ä¶ ## 5 21 Chuck Liddell Himself 444‚Äì‚Ä¶ LABF16 \u0026quot;\\\u0026quot;The Great W‚Ä¶ ## 6 21 Marcia Wallace Edna Krab‚Ä¶ 444‚Äì‚Ä¶ LABF16 \u0026quot;\\\u0026quot;The Great W‚Ä¶ ## 7 21 Marcia Wallace Edna Krab‚Ä¶ 445‚Äì‚Ä¶ LABF14 \u0026quot;\\\u0026quot;Treehouse o‚Ä¶ ## 8 21 Marcia Wallace Edna Krab‚Ä¶ 446‚Äì‚Ä¶ LABF17 \u0026quot;\\\u0026quot;The Devil W‚Ä¶ ## 9 21 Jonah Hill Andy Hami‚Ä¶ 447‚Äì‚Ä¶ LABF18 \u0026quot;\\\u0026quot;Pranks and ‚Ä¶ ## 10 21 Marcia Wallace Edna Krab‚Ä¶ 447‚Äì‚Ä¶ LABF18 \u0026quot;\\\u0026quot;Pranks and ‚Ä¶ ## # ‚Ä¶ with 666 more rows That‚Äôs what we want. Let‚Äôs assign that as an object:\nsimpsons = table %\u0026gt;% pluck(2) Cleaning up the data and making the plot The column names of this table are hard to work with. Let‚Äôs use the clean_names function on our table and assign that to another object called clean_simpsons.\nclean_simpsons = simpsons %\u0026gt;% clean_names() Finally, we can use our tidyverse know-how to calculate how many times each Guest Star has appeared on the Simpson‚Äôs, and filter the data down to just those who have appeared more than twice. We can then make a plot showing how many times each of these guest stars has appeared on the show.\nplot_simpsons = clean_simpsons %\u0026gt;% group_by(guest_star) %\u0026gt;% tally() %\u0026gt;% filter(n \u0026gt; 2) ggplot(plot_simpsons, aes(x = reorder(guest_star, n), y = n)) + geom_col() + coord_flip() Done! Here are some other good ones to try:\nhttps://en.wikipedia.org/wiki/List_of_nicknames_used_by_Donald_Trump https://en.wikipedia.org/wiki/List_of_helicopter_prison_escapes https://en.wikipedia.org/wiki/Passengers_of_the_Titanic https://en.wikipedia.org/wiki/Last_meal https://en.wikipedia.org/wiki/List_of_consorts_of_the_Ottoman_sultans https://en.wikipedia.org/wiki/List_of_people_who_died_climbing_Mount_Everest ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"14293c7538a545b428cb9f5330dfd847","permalink":"/reference/scraping-websites/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reference/scraping-websites/","section":"reference","summary":"Intro Pulling the table Cleaning up the data and making the plot Intro library(tidyverse) library(rvest) library(janitor) There‚Äôs a lot of information on the internet. Sometimes this information is nicely formatted, which means we can scrape it from the internet fairly easily.\nTake a look at the table on this page of Simpsons guest star appearances: https://en.wikipedia.org/wiki/List_of_The_Simpsons_guest_stars\nWe‚Äôre gonna pull this table from the internet into R. You‚Äôll need the rvest and janitor packages.","tags":null,"title":"How to scrape websites","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Bootstrapping concepts Using the infer package Bootstrapping averages Bootstrapping regression coefficients Standard errors and confidence intervals Hypothesis testing Hypothesis testing: permutation Alpha-levels (standards of evidence) Hypothesis testing: confidence intervals Alpha-levels: tradeoffs In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nday2-uncertainty.R\nBootstrapping concepts library(tidyverse) library(moderndive) library(infer) library(socviz) library(broom) Remember, our estimate is based on a sample from some population, and each sample is going to give us a different estimate. This means our estimates will vary from sample to sample. How can we quantify this variability?\nOne approach is via bootstrapping, where we:\nSimulate many new datasets out of our original dataset Estimate the thing we want to estimate in each of those bootstrapped samples Look at the distribution of estimates across bootstrap samples That distribution of bootstrapped estimates gives us a sense for how much an estimate might vary from sample to sample.\nUsing the infer package Bootstrapping averages Let‚Äôs do this with the infer package, to estimate the number of kids the average American has.\ngss_sm %\u0026gt;% # specify the outcome variable specify(response = childs) %\u0026gt;% # generate the bootstrapped samples generate(reps = 1000, type = \u0026quot;bootstrap\u0026quot;) ## Response: childs (numeric) ## # A tibble: 2,859,000 √ó 2 ## # Groups: replicate [1,000] ## replicate childs ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 0 ## 2 1 2 ## 3 1 0 ## 4 1 3 ## 5 1 4 ## 6 1 1 ## 7 1 0 ## 8 1 5 ## 9 1 0 ## 10 1 0 ## # ‚Ä¶ with 2,858,990 more rows Notice how each of the 1,000 bootstrapped samples has the same number of observations as the original dataset.\nThe above is equivalent to doing this 1,000 times:\ngss_sm %\u0026gt;% # subset down to just kids select(childs) %\u0026gt;% # sample with replacement, same size as original dataset sample_n(nrow(gss_sm), replace = TRUE) ## # A tibble: 2,867 √ó 1 ## childs ## \u0026lt;dbl\u0026gt; ## 1 5 ## 2 0 ## 3 2 ## 4 0 ## 5 1 ## 6 0 ## 7 3 ## 8 1 ## 9 0 ## 10 1 ## # ‚Ä¶ with 2,857 more rows We can then calculate the average number of kids in each of those 1,000 bootstraps:\nboot_kids = gss_sm %\u0026gt;% # specify the outcome variable specify(response = childs) %\u0026gt;% # generate the bootstrapped samples generate(reps = 1000, type = \u0026quot;bootstrap\u0026quot;) %\u0026gt;% # find the average # of kids in each bootstrap sample calculate(stat = \u0026quot;mean\u0026quot;) boot_kids ## # A tibble: 1,000 √ó 2 ## replicate stat ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1.83 ## 2 2 1.88 ## 3 3 1.84 ## 4 4 1.86 ## 5 5 1.79 ## 6 6 1.90 ## 7 7 1.86 ## 8 8 1.82 ## 9 9 1.86 ## 10 10 1.88 ## # ‚Ä¶ with 990 more rows stat is the average number of kids in each bootstrap (replicate).\nWe can look at the distribution to get a sense for the variability in the estimates:\nggplot(boot_kids, aes(x = stat)) + geom_density(color = \u0026quot;white\u0026quot;, fill = \u0026quot;coral\u0026quot;, alpha = .7) + theme_bw() + labs(title = \u0026quot;Average number of kids across bootstraps\u0026quot;, x = NULL, y = NULL) + scale_x_continuous(limits = c(1, 3)) Notice how almost all bootstrapped estimates of the average number of kids are between 1.75 and 2, and the vast majority are in a narrower range than that.\nWe can also quantify this variation by taking the standard deviation of stat:\nboot_kids %\u0026gt;% summarise(se = sd(stat)) ## # A tibble: 1 √ó 1 ## se ## \u0026lt;dbl\u0026gt; ## 1 0.0312 This is also known as the standard error.\nVariability gets bigger as sample size gets smaller The process above gives us a sense of the variability in our estimate of the average number of kids in the US, based on our survey of \\(\\approx\\) 2,800 people. What if we had a much smaller survey? Say 100 people?\nWe can mimic that below by taking 100 random people from gss_sm and pretending that‚Äôs our full survey:\nboot_kids = gss_sm %\u0026gt;% # smaller survey of only 100 people sample_n(100) %\u0026gt;% # specify the outcome variable specify(response = childs) %\u0026gt;% # generate the bootstrapped samples generate(reps = 1000, type = \u0026quot;bootstrap\u0026quot;) %\u0026gt;% # find the average # of kids in each bootstrap sample calculate(stat = \u0026quot;mean\u0026quot;) Notice how much wider this distribution is than the one above. The variability in our bootstrapped estimates is much higher!\nggplot(boot_kids, aes(x = stat)) + geom_density(color = \u0026quot;white\u0026quot;, fill = \u0026quot;coral\u0026quot;, alpha = .7) + theme_bw() + labs(title = \u0026quot;Average number of kids across bootstraps\u0026quot;, x = NULL, y = NULL) + scale_x_continuous(limits = c(1, 3)) You can quantify this too; notice how much bigger the standard error is of this much smaller survey:\nboot_kids %\u0026gt;% summarise(se = sd(stat)) ## # A tibble: 1 √ó 1 ## se ## \u0026lt;dbl\u0026gt; ## 1 0.146 Bootstrapping regression coefficients We can use bootstrapping to approximate the variability in lots of things we might want to estimaet, including coefficients from regression.\nSay we wanted to look at the effect of age on whether or not someone has children:\nlm(childs ~ age, data = gss_sm) %\u0026gt;% tidy() ## # A tibble: 2 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 0.153 0.0858 1.79 7.40e- 2 ## 2 age 0.0345 0.00164 21.0 1.83e-91 Remember this estimate comes from a sample. Other samples will give us different estimates. We can get a sense for how much coefficients will vary across samples with bootstrapping:\nboot_age = gss_sm %\u0026gt;% # specify is now Y ~ X specify(childs ~ age) %\u0026gt;% generate(reps = 1000, type = \u0026quot;bootstrap\u0026quot;) %\u0026gt;% # \u0026quot;slope\u0026quot; is another word for coefficient calculate(stat = \u0026quot;slope\u0026quot;) Notice how the code looks a bit different: we put childs ~ age in specify() and we gotta tell R to calculate the ‚Äúslope‚Äù, or coefficient, from lm(childs ~ age).\nWe can plot:\nggplot(boot_age, aes(x = stat)) + geom_density(color = \u0026quot;white\u0026quot;, fill = \u0026quot;coral\u0026quot;, alpha = .7) + theme_bw() + labs(title = \u0026quot;Estimate of relationship between age and number of kids\u0026quot;, subtitle = \u0026quot;Coefficient estimates across bootstrapped samples.\u0026quot;, x = NULL, y = NULL) Notice how coefficient estimates vary a lot, from .03 to almost .04.\nStandard errors and confidence intervals The distributions we get from bootstrapping give us a sense for the variability in our sample estimates. We can quantify that variability in two ways:\nOne is through the standard error (the standard deviation of the bootstrapped sample estimates):\nboot_age %\u0026gt;% summarise(se = sd(stat)) ## # A tibble: 1 √ó 1 ## se ## \u0026lt;dbl\u0026gt; ## 1 0.00167 The other is the confidence interval, which provides our ‚Äúbest guess‚Äù of the thing we are trying to estimate:\nboot_age %\u0026gt;% get_confidence_interval(level = .95) ## # A tibble: 1 √ó 2 ## lower_ci upper_ci ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0.0313 0.0376 The standard is 95%: so the two numbers give us the upper and lower bound of the middle 95% of the bootstrapped distribution.\nNotice that as the confidence increases, the bounds get larger:\nboot_age %\u0026gt;% get_confidence_interval(level = .99) ## # A tibble: 1 √ó 2 ## lower_ci upper_ci ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0.0302 0.0387 As the confidence decreases, the bounds get smaller:\nboot_age %\u0026gt;% get_confidence_interval(level = .5) ## # A tibble: 1 √ó 2 ## lower_ci upper_ci ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0.0333 0.0357 Hypothesis testing Remember, hypothesis testing is about how we decide between two competing hypotheses ‚Äì or theories about the relationship between two variables ‚Äì using data.\nTake the example from class, on whether bicep size predicts conservative ideology. The two competing hypotheses are:\nNull hypothesis: there is no relationship between biceps and conservative ideology Alternative hypothesis: there is a positive relationship between biceps and conservative ideology We make up fake data below:\nset.seed(23424) # fake bicep data fake = tibble(person = 1:100, bicep = rnorm(100), conservative = runif(100)*100 + 2*bicep) We estimate the relationship between bicep and ideology:\n# what is the effect? lm(conservative ~ bicep, data = fake) %\u0026gt;% summary() ## ## Call: ## lm(formula = conservative ~ bicep, data = fake) ## ## Residuals: ## Min 1Q Median 3Q Max ## -45.688 -24.505 -5.035 28.053 54.741 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 46.839 2.892 16.197 \u0026lt;2e-16 *** ## bicep 3.996 2.754 1.451 0.15 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 28.92 on 98 degrees of freedom ## Multiple R-squared: 0.02103, Adjusted R-squared: 0.01104 ## F-statistic: 2.105 on 1 and 98 DF, p-value: 0.15 Remember, this estimate is based on one sample. How much might estimates vary? We can use bootstrapping to get a sense:\nboot_bicep = fake %\u0026gt;% specify(conservative ~ bicep) %\u0026gt;% generate(reps = 1000, type = \u0026quot;bootstrap\u0026quot;) %\u0026gt;% calculate(stat = \u0026quot;slope\u0026quot;) ggplot(boot_bicep, aes(x = stat)) + geom_density(color = \u0026quot;white\u0026quot;, fill = \u0026quot;coral\u0026quot;, alpha = .7) + theme_bw() + labs(title = \u0026quot;Estimate of relationship between bicep size and ideology score\u0026quot;, subtitle = \u0026quot;Coefficient estimates across bootstrapped samples.\u0026quot;, x = NULL, y = NULL) Notice how much the coefficient can vary: in some cases as large as 10 or more, in others 0, and in some cases even negative.\nHow do we decide, based on this distribution, whether there is in fact that a stable relationship between biceps and ideology?\nHypothesis testing: permutation One way to decide is to simulate what the world might look like under the null hypothesis ‚Äì a world where biceps don‚Äôt affect ideology.\nWe can do this by randomly ‚Äúshuffling‚Äù or permuting the values in our bicep variable. Why? This mimics the idea that if bicep size and ideology are unrelated, you could completely alter one variable without affecting the other. So we:\n‚Äúshuffle‚Äù or permute the bicep variable estimate lm(conservative ~ bicep), store coefficient on bicep repeat N times # permutation based hypothesis testing null_biceps = fake %\u0026gt;% # specify is now Y ~ X specify(conservative ~ bicep) %\u0026gt;% # define null hypothesis: \u0026quot;independence\u0026quot; hypothesize(null = \u0026quot;independence\u0026quot;) %\u0026gt;% # now we do \u0026quot;permute\u0026quot; instead of bootstrap generate(reps = 1000, type = \u0026quot;permute\u0026quot;) %\u0026gt;% # \u0026quot;slope\u0026quot; is another word for coefficient calculate(stat = \u0026quot;slope\u0026quot;) null_biceps ## # A tibble: 1,000 √ó 2 ## replicate stat ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 3.60 ## 2 2 3.28 ## 3 3 1.73 ## 4 4 0.390 ## 5 5 2.15 ## 6 6 5.20 ## 7 7 -5.17 ## 8 8 -4.43 ## 9 9 -2.34 ## 10 10 1.15 ## # ‚Ä¶ with 990 more rows Each row here is the estimated coefficient of bicep from a permuted sample ‚Äì a sample where the values of bicep have been shuffled. Look at the distribution:\nggplot(null_biceps, aes(x = stat)) + geom_histogram(color = \u0026quot;white\u0026quot;, fill = \u0026quot;coral\u0026quot;) + theme_bw() + labs(title = \u0026quot;The Simulated Null Distribution\u0026quot;, subtitle = \u0026quot;What we would observe in a world where biceps and ideology are unrelated.\u0026quot;, x = \u0026quot;Permuted coefficient estimates from lm(affairs ~ children)\u0026quot;, y = NULL) This is our simulation of what we might observe under the null hypothesis ‚Äì that there is no relationship between biceps and ideology. Two key takeaways here:\nAs we would expect, most of our simulated coefficient estimates are close to zero. This makes sense! The null hypothesis is precisely that there is no relationship between the two (e.g., that the coefficient is not greater than zero!).\nEven in a world where the null is true, you can still get pretty large coefficient estimates by chance, even as large as -10 and +10.\nPoint (2) is really important: totally by chance, two variables that are unrelated can still have strong positive or negative correlations. It is unlikely that this happens, but it‚Äôs still possible.\nWith a simulation of what the world would like under the null hypothesis, we can turn back to our original estimate:\nlm(conservative ~ bicep, data = fake) %\u0026gt;% moderndive::get_regression_table() ## # A tibble: 2 √ó 7 ## term estimate std_error statistic p_value lower_ci upper_ci ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 intercept 46.8 2.89 16.2 0 41.1 52.6 ## 2 bicep 4.00 2.75 1.45 0.15 -1.47 9.46 How likely is it that our estimate would have occurred by chance?\nggplot(null_biceps, aes(x = stat)) + geom_histogram(color = \u0026quot;white\u0026quot;, fill = \u0026quot;coral\u0026quot;) + theme_bw() + labs(title = \u0026quot;The Simulated Null Distribution\u0026quot;, subtitle = \u0026quot;What we would observe in a world where biceps and ideology are unrelated.\u0026quot;, x = \u0026quot;Permuted coefficient estimates from lm(affairs ~ children)\u0026quot;, y = NULL) + geom_vline(xintercept = 3.996, lty = 2, color = \u0026quot;black\u0026quot;, size = 2) Our estimate is a fair bit larger than what you would expect to observe under the null hypothesis. We can calculate exactly how much larger using the p-value. We set direction = right because we want to know how much larger the estimate is than expected.\nget_p_value(null_biceps, obs_stat = 3.996, direction = \u0026quot;both\u0026quot;) ## # A tibble: 1 √ó 1 ## p_value ## \u0026lt;dbl\u0026gt; ## 1 0.168 The p-value is .084, meaning that only 8.4% of the estimates we got by chance are as large or larger than our original result. In other words, our estimate is larger than 84% of the results we could observe by chance.\nWe can calculate this ‚Äúby hand‚Äù too, like so:\nnull_biceps %\u0026gt;% mutate(bigger = ifelse(stat \u0026gt; 3.996, \u0026quot;yes\u0026quot;, \u0026quot;no\u0026quot;)) %\u0026gt;% group_by(bigger) %\u0026gt;% tally() %\u0026gt;% mutate(percent = n/sum(n)) ## # A tibble: 2 √ó 3 ## bigger n percent ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 no 916 0.916 ## 2 yes 84 0.084 84% larger than we might observe by chance ‚Äì sounds like our result is unusually large, and unlikely to be the result of random chance. But is it unlikely enough for us to be confident?\nAlpha-levels (standards of evidence) Remember the standard and totally arbitrary alpha-level accepted in the scientific community is .05. This means that p-values lower than .05 are considered too small to be the result of random chance, while p-values higher than that are considered too large to feel confident in. Arbitrary? Yes.\nSince our p-value of .084 is larger than the .05 standard (the alpha-level), we would fail to reject the null hypothesis. In other words, the result is too plausible in a world where null hypothesis is true for us to reject it!\nHypothesis testing: confidence intervals A different, and much more straightforward way, to do hypothesis testing is to bootstrap confidence intervals and see if they exclude 0. Let‚Äôs do the bootstrap.\nboot_bicep = fake %\u0026gt;% specify(conservative ~ bicep) %\u0026gt;% generate(reps = 1000, type = \u0026quot;boot\u0026quot;) %\u0026gt;% calculate(stat = \u0026quot;slope\u0026quot;) Here is the distribution of bootstrapped estimates from our data:\nggplot(boot_bicep, aes(x = stat)) + geom_histogram(color = \u0026quot;white\u0026quot;, fill = \u0026quot;coral\u0026quot;) + theme_bw() + labs(title = \u0026quot;Distribution of bootstrapped estimates\u0026quot;, subtitle = \u0026quot;How the relationship between biceps and ideology might vary across samples.\u0026quot;, x = \u0026quot;Bootstrapped coefficient estimates from lm(conservative ~ bicep)\u0026quot;, y = NULL) Here‚Äôs the standard error:\nboot_bicep %\u0026gt;% summarise(se = sd(stat)) ## # A tibble: 1 √ó 1 ## se ## \u0026lt;dbl\u0026gt; ## 1 2.78 Here‚Äôs the 95% confidence interval:\nget_confidence_interval(boot_bicep, level = .95) ## # A tibble: 1 √ó 2 ## lower_ci upper_ci ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 -1.58 9.23 Notice this interval includes 0. This means that the range of values that are our ‚Äúbest guess‚Äù for the effect of biceps on ideology include the possibility that there is no effect (or that the effect is negative). Following the standard of using .05 as the threshold, we would fail to reject the null hypothesis of no effect of biceps on ideology.\nHere‚Äôs the confidence interval again, with shading:\nggplot(boot_bicep, aes(x = stat)) + geom_histogram(color = \u0026quot;white\u0026quot;, fill = \u0026quot;coral\u0026quot;) + theme_bw() + labs(title = \u0026quot;Distribution of bootstrapped estimates\u0026quot;, subtitle = \u0026quot;How the relationship between biceps and ideology might vary across samples.\u0026quot;, x = \u0026quot;Bootstrapped coefficient estimates from lm(conservative ~ bicep)\u0026quot;, y = NULL) + annotate(geom = \u0026quot;rect\u0026quot;, xmin = get_confidence_interval(boot_bicep)[[\u0026quot;lower_ci\u0026quot;]], xmax = get_confidence_interval(boot_bicep)[[\u0026quot;upper_ci\u0026quot;]], ymin = 0, ymax = Inf, fill = \u0026quot;#2ECC40\u0026quot;, alpha = 0.25) Alpha-levels: tradeoffs Remember, the (abitrary) convention for deciding between competing hypotheses is a p-value less than .05; that .05 threshold is known as the alpha-level. An important thing to remember is that there is a trade-off in the size of the alpha-level:\nthe bigger the alpha-level, the lower our standard of evidence for rejecting the null, which means a lower chance of Type 2 error (e.g., letting the guilty go free) and a higher chance of Type 1 error (e.g., convicting the innocent)\nthe smaller the alpha-level, the higher our standard of evidence for rejecting the null, which means a higher chance of Type 2 error and a lower chance of Type 1 error\nLet‚Äôs use simulation to see this. Let‚Äôs pretend once again that gss_sm is the whole of the American public. We want to estimate the effect of age on children in this population. H1 is that people who are older are more likely to have children than people who are younger. H0 (the null) is that people who are older don‚Äôt have children at higher rates than people who are younger.\nWe can know the exact effect of age on children in this made-up example:\nlm(childs ~ age, data = gss_sm) %\u0026gt;% tidy() ## # A tibble: 2 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 0.153 0.0858 1.79 7.40e- 2 ## 2 age 0.0345 0.00164 21.0 1.83e-91 The true effect size is .0345. So we should reject the null, since the coefficient is not zero (or less than zero).\nNow, say we have a random sample of 200 people from this population. We can take a sample, estimate 95% confidence interval below:\ngss_sm %\u0026gt;% drop_na() %\u0026gt;% sample_n(200) %\u0026gt;% specify(childs ~ age) %\u0026gt;% generate(reps = 1000, type = \u0026quot;bootstrap\u0026quot;) %\u0026gt;% calculate(stat = \u0026quot;slope\u0026quot;) %\u0026gt;% get_confidence_interval() ## # A tibble: 1 √ó 2 ## lower_ci upper_ci ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0.0198 0.0475 What if we do this many times? How many times will our confidence interval\nget_ci = function(x) { ci = x %\u0026gt;% specify(childs ~ age) %\u0026gt;% generate(reps = 1000, type = \u0026quot;bootstrap\u0026quot;) %\u0026gt;% calculate(stat = \u0026quot;slope\u0026quot;) %\u0026gt;% get_confidence_interval() return(ci) } gss_sm %\u0026gt;% select(childs, age) %\u0026gt;% rep_sample_n(size = 200, reps = 100, replace = FALSE) %\u0026gt;% nest() %\u0026gt;% mutate(cis = map(data, get_ci)) ## # A tibble: 100 √ó 3 ## # Groups: replicate [100] ## replicate data cis ## \u0026lt;int\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; ## 1 1 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 2 2 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 3 3 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 4 4 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 5 5 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 6 6 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 7 7 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 8 8 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 9 9 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## 10 10 \u0026lt;tibble [200 √ó 2]\u0026gt; \u0026lt;tibble [1 √ó 2]\u0026gt; ## # ‚Ä¶ with 90 more rows ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"810a569b8c62e38b3e1c98ad5ba3b29f","permalink":"/class/bootstrap/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/bootstrap/","section":"class","summary":"In-class example Bootstrapping concepts Using the infer package Bootstrapping averages Bootstrapping regression coefficients Standard errors and confidence intervals Hypothesis testing Hypothesis testing: permutation Alpha-levels (standards of evidence) Hypothesis testing: confidence intervals Alpha-levels: tradeoffs In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.","tags":null,"title":"Bootstrap","type":"docs"},{"authors":null,"categories":null,"content":" Optional Slides Tuesday Optional Chapter 7 in ModernDive\nCh.8 in ModernDive\nSlides Tuesday Class slides here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3865e158bb30f32cdf532a7d8ef8a1d0","permalink":"/reading/11-bootstrap/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/11-bootstrap/","section":"reading","summary":"Optional Slides Tuesday Optional Chapter 7 in ModernDive\nCh.8 in ModernDive\nSlides Tuesday Class slides here","tags":null,"title":"Bootstrap","type":"docs"},{"authors":null,"categories":null,"content":" In-class example In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nday1-causality.R day2-causality.R ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c0fe5eab16b611da5e17a892b858d8ff","permalink":"/class/causality/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/causality/","section":"class","summary":" In-class example In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nday1-causality.R day2-causality.R ","tags":null,"title":"Causality","type":"docs"},{"authors":null,"categories":null,"content":" Recommended Slides Tuesday Thursday Recommended this video from Khan Academy\nIntroduction in Causal Inference: The Mixtape1\nSlides Tuesday Class slides here\nThursday Class slides here\nThis reading is mathy-er than what we‚Äôve covered so far. It also features code from STATA, which we don‚Äôt use. Don‚Äôt worry about that so much; we will focus on broad concepts/ideas.‚Ü©Ô∏é\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"18392717f6bb4692a5abf7bf3c1ad38c","permalink":"/reading/07-causal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/07-causal/","section":"reading","summary":"Recommended Slides Tuesday Thursday Recommended this video from Khan Academy\nIntroduction in Causal Inference: The Mixtape1\nSlides Tuesday Class slides here\nThursday Class slides here\nThis reading is mathy-er than what we‚Äôve covered so far. It also features code from STATA, which we don‚Äôt use. Don‚Äôt worry about that so much; we will focus on broad concepts/ideas.‚Ü©Ô∏é","tags":null,"title":"Causality","type":"docs"},{"authors":null,"categories":null,"content":" Confounding Marriage, divorce, age, and confounding Backdoors and front-doors The experimental gold standard Easy DAGs When things go wrong: Elemental confounds forks pipes collider More complicated DAGs Confounding Remember that we‚Äôre always trying to estimate the effect of some treatment, X, on some outcome, Y. The problem is that simply looking at the relationship between X and Y can lead you astray, since lots of things are correlated in the world that have no causal relationship (e.g., number of shark attacks and amount of ice cream consumed are probably positively correlated; but obviously ice cream does not cause shark attacks!).\nThis ‚Äúbeing led astray‚Äù by data is what we call confounding. What we want to do in this part of the class is use causal models to figure out how to estimate the effect of X on Y, and avoid confounding.\nMarriage, divorce, age, and confounding Remember in class that we can have a DAG like the below, where the age (A) at which people get married has a negative causal effect on the marriage (M) rate (places where people wait till later to get married have lower marriage rates) and a negative causal effect on the divorce (D) rate (places where people wait to get married have lower divorce rates).\nlibrary(ggdag) library(tidyverse) library(broom) set.seed(1990) dagify(D ~ A, M ~ A) %\u0026gt;% ggdag(layout = \u0026quot;circle\u0026quot;) + theme_dag() Note that there is no arrow from marriage rate (M) to divorce (D). We have explicitly made our data so that there is no causal effect of M on D. And yet! this DAG will produce data that shows a strong relationship between M and D.\nFaking some data helps us see this:\nfake = tibble(age = rnorm(100), marriage = -2*age + rnorm(100), divorce = -2*age + rnorm(100)) ggplot(fake, aes(x = marriage, y = divorce)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) + theme_light() We end up with a confounded estimate of the effect of marriage on divorce.\nBackdoors and front-doors The reason that the above DAG produces a confounded estimate of marriage on divorce is that there is a backdoor path from marriage to divorce, going through age. A backdoor path is a path linking our X and Y variables in a non-causal way. If we don‚Äôt close backdoor paths, our estimate of the effect of X (marriage) on Y (divorce) will be confounded. To close the backdoor path we must control for age.\nFront-door paths are the ways in which X causes Y. They might be direct (as in an arrow from X to Y), or indirect, as in an arrow from X, to Z, to Y. We want to keep front doors open and not accidentally control for them.\nThe experimental gold standard Remember that in an experiment, we randomize assignment to some treatment, measure an outcome we care about, and compare whether the units that got the treatment have better or worse results on the outcome than the group that didn‚Äôt get the treatment.\nWe can simulate a fake experiment (on rats) using R:\nrats = tibble(rat_id = 1:200, vaccine = sample(c(1, 0), size = 200, replace = TRUE), social = sample(c(1, 0), size = 200, replace = TRUE)) %\u0026gt;% mutate(covid_levels = -2*vaccine + 3*social + rnorm(200)) rats ## # A tibble: 200 x 4 ## rat_id vaccine social covid_levels ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 1 0 -2.35 ## 2 2 0 1 3.74 ## 3 3 1 0 1.38 ## 4 4 1 0 -1.82 ## 5 5 1 1 1.90 ## 6 6 1 1 2.15 ## 7 7 1 0 -1.60 ## 8 8 1 1 0.923 ## 9 9 1 0 -2.90 ## 10 10 0 1 4.34 ## # ‚Ä¶ with 190 more rows Note that in making up our data, we decided that the vaccine would have an effect of -2 on covid_levels.\nWe can estimate the effect of the vaccine on COVID using regression:\n# estimate treatment effect m1 = lm(covid_levels ~ vaccine, data = rats) tidy(m1) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 1.56 0.181 8.64 1.89e-15 ## 2 vaccine -2.06 0.250 -8.26 2.05e-14 Note the estimated coefficient on the vaccine is pretty close to the true effect (-2). The reason is because there is no backdoor path, no third variable, or set of variables, causing both the vaccine and COVID levels.\nEasy DAGs Remember, unless otherwise specified, when we are looking at DAGs we assume that X is the treatment variable and Y is the outcome variable.\ndag = dagify(Y ~ X) ggdag(dag) + theme_dag_blank() No need to close anything here.\ndag = dagify(Y ~ X + B + A + C + G, B ~ A + C, G ~ C) ggdag(dag) + theme_dag_blank() No need to close anything here either. All we care about is estimating the effect of X on Y; it doesn‚Äôt matter that other things also cause Y!\nWhen things go wrong: Elemental confounds We talked about three common scenarios in which confounding can take place: forks, pipes, and colliders.\nforks Remember, the fork looks like this:\nconfounder_triangle(x = \u0026quot;Has Huge beard\u0026quot;, y = \u0026quot;Amount of basketball watched\u0026quot;, z = \u0026quot;Love James Harden\u0026quot;) %\u0026gt;% ggdag(use_labels = \u0026quot;label\u0026quot;) + theme_dag() Need to control for loving James harden!\nOr like this:\nconfounder_triangle(x = \u0026quot;Marriage rate\u0026quot;, y = \u0026quot;Divorce rate\u0026quot;, z = \u0026quot;Median age at marriage\u0026quot;, x_y_associated = TRUE) %\u0026gt;% ggdag(use_labels = \u0026quot;label\u0026quot;) + theme_dag() Need to control for median age at marriage!\npipes The pipe looks like this and it‚Äôs an example of why we shouldn‚Äôt close front-door paths:\ndagify(Y ~ B + G, B ~ X, labels = c(\u0026quot;Y\u0026quot; = \u0026quot;Plant growth\u0026quot;, \u0026quot;B\u0026quot; = \u0026quot;Good bacteria\u0026quot;, \u0026quot;G\u0026quot; = \u0026quot;Starting size\u0026quot;, \u0026quot;X\u0026quot; = \u0026quot;Fertilizer\u0026quot;)) %\u0026gt;% ggdag(use_labels = \u0026quot;label\u0026quot;) + theme_dag_blank() If we control for presence of good bacteria we are closing front-door from Fertilizer to Plant Growth (which is bad)!\ncollider The collider looks like this:\ncollider_triangle(x = \u0026quot;Qualtiy research\u0026quot;, y = \u0026quot;Surprising results\u0026quot;, m = \u0026quot;Published\u0026quot;) %\u0026gt;% ggdag(use_labels = \u0026quot;label\u0026quot;) + theme_dag_blank() If we control for M here we are creating a backdoor path from X to Y. This is bad!\nMore complicated DAGs dag = dagify(Y ~ X + P + A + I, X ~ P, exposure = \u0026quot;X\u0026quot;, outcome = \u0026quot;Y\u0026quot;) ggdag(dag) + theme_dag_blank() Here, we need to control for P since it is a backdoor from X to Y. Note that there are other variables that also cause Y (I and A) but we don‚Äôt need to control for them to estimate the effect of X on Y.\ndag = dagify(support ~ anxiety + event, anxiety ~ event, labels = c(\u0026quot;support\u0026quot; = \u0026quot;Support for torture\u0026quot;, \u0026quot;anxiety\u0026quot; = \u0026quot;Level of anxiety\u0026quot;, \u0026quot;event\u0026quot; = \u0026quot;Terrorism event\u0026quot;) ) ggdag(dag, text = FALSE, use_labels = \u0026quot;label\u0026quot;) + theme_dag_blank() In this example from class, we want to know the effect of experiencing terrorism on support for torture. Notice the effect of terrorism on support for torture is both direct and indirect (via heightened anxiety). This is an example of a pipe; if we control for anxiety here, we are effectively controlling away part of the effect of terrorism on support for torture.\nsmoking_ca_dag = dagify(cardiacarrest ~ cholesterol, cholesterol ~ smoking + weight, smoking ~ unhealthy, weight ~ unhealthy, labels = c(\u0026quot;cardiacarrest\u0026quot; = \u0026quot;Cardiac\\n Arrest\u0026quot;, \u0026quot;smoking\u0026quot; = \u0026quot;Drugs\u0026quot;, \u0026quot;cholesterol\u0026quot; = \u0026quot;Cholesterol\u0026quot;, \u0026quot;unhealthy\u0026quot; = \u0026quot;Unhealthy\\n Lifestyle\u0026quot;, \u0026quot;weight\u0026quot; = \u0026quot;Weight\u0026quot;), latent = \u0026quot;unhealthy\u0026quot;, exposure = \u0026quot;smoking\u0026quot;, outcome = \u0026quot;cardiacarrest\u0026quot;) ggdag(smoking_ca_dag, text = FALSE, use_labels = \u0026quot;label\u0026quot;) + theme_dag_blank() In this example we want to know the effect of drug use on cardiac arrest. Notice there is a backdoor path through unhealthy life styles, to weight, to cholesterol, and onto cardiac arrest. We want to close that backdoor path: we can control for unhealthy lifestyle, OR weight (notice how both break the chain!).\nBut there is also a pipe here! If we were to accidentally control for cholesterol we would be closing a front-door path (bad). So we need to avoid doing that.\ndag = dagify(y ~ x + c, x ~ u, u ~ a, c ~ a, b ~ u + c, exposure = \u0026quot;x\u0026quot;, outcome = \u0026quot;y\u0026quot;) ggdag(dag) + theme_dag_blank() Notice the backdoor path: X \u0026lt;- U -\u0026gt; A -\u0026gt; C -\u0026gt; Y. To close it and break the chain we can control for U, A, or C.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d5b02c94127f38ec2f3fd39aac4c88f1","permalink":"/class/confounds/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/confounds/","section":"class","summary":"Confounding Marriage, divorce, age, and confounding Backdoors and front-doors The experimental gold standard Easy DAGs When things go wrong: Elemental confounds forks pipes collider More complicated DAGs Confounding Remember that we‚Äôre always trying to estimate the effect of some treatment, X, on some outcome, Y. The problem is that simply looking at the relationship between X and Y can lead you astray, since lots of things are correlated in the world that have no causal relationship (e.","tags":null,"title":"Confounds","type":"docs"},{"authors":null,"categories":null,"content":"Instructions Download this: ps-controls right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cb4f7450ac0031ddbc3b6d2997aa4ece","permalink":"/assignment/ps-controls/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/ps-controls/","section":"assignment","summary":"Instructions Download this: ps-controls right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","tags":null,"title":"Controls","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Drawing lines (geom_smooth) ggcorrplot Draw the line Convince yourself IR Econ In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù\nday1-models.R day2-models.R Drawing lines (geom_smooth) Why draw trend lines? Trend lines give us a good, educated guess as to what the value of a Y variable is given some value of X. We can draw a trend line (or line of best fit) using geom_smooth, as below. Notice method = \"lm\".\n# libraries library(tidyverse) # mtcars ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ggcorrplot # libraries library(tidyverse) library(socviz) library(fivethirtyeight) library(gapminder) library(nycflights13) library(ggcorrplot) library(juanr) library(palmerpenguins) Look at the correlations:\n# switch out gapminder with a dataset you want below therm %\u0026gt;% # correlation only works with numeric columns; keep only those select(where(is.numeric)) %\u0026gt;% # the cor() function doesn\u0026#39;t take NA; drop them all drop_na() %\u0026gt;% # get the correlation cor() %\u0026gt;% # plot the correlation ggcorrplot(lab = TRUE) Draw the line # draw a line: alter the intercept and slope in geom_abline() # to draw the line ggplot() + geom_abline(intercept = 1, slope = 2, size = 1) + # change the limits on the x and y-axis scale_x_continuous(limits = c(-10, 10)) + scale_y_continuous(limits = c(-10, 10)) + # add a vertical and horizontal line at 0 geom_hline(yintercept = 0, lty = 2) + geom_vline(xintercept = 0, lty = 2) + theme_bw() Convince yourself Make the scatterplot:\n# convince yourself about the line of best fit: run this code below # set the seed set.seed(1990) # make the fake data df = tibble(x = rnorm(50, mean = 10), y = 3 + 2*x + rnorm(50)) # line of best fit? model = lm(y ~ x, df) true = tibble(true_intercept = coef(model)[1], true_slope = coef(model)[2]) ggplot(data = df, aes(x = x, y = y)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) IR Econ The plot\nir_1959 = trade %\u0026gt;% filter(year == 2008) ggplot(ir_1959, aes(x = imports, y = exports, label = country)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) + geom_text() Estimate a model, and interpret:\nlibrary(broom) igo_pop = lm(exports ~ pop, data = trade) tidy(igo_pop) ## # A tibble: 2 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 13322. 1023. 13.0 1.81e-38 ## 2 pop 0.000393 0.00000920 42.7 0 Penguins regression:\npenguins_model = lm(body_mass_g ~ species, data = penguins) tidy(penguins_model) ## # A tibble: 3 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 3701. 37.6 98.4 2.49e-251 ## 2 speciesChinstrap 32.4 67.5 0.480 6.31e- 1 ## 3 speciesGentoo 1375. 56.1 24.5 5.42e- 77 Interpretation:\nChinstrap penguins weigh 32 more grams, on average, than Adelie penguins. Gentoo penguins weigh 1,375 more grams, on average, than Adelie penguins. Adelie penguins weigh, on average, 3,700 grams. another one:\nlm(tvhours ~ race, data = gss_cat) %\u0026gt;% tidy() ## # A tibble: 3 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 2.76 0.0792 34.9 3.90e-253 ## 2 raceBlack 1.42 0.100 14.1 5.90e- 45 ## 3 raceWhite 0.00894 0.0838 0.107 9.15e- 1 Interpretation:\nBlack respondents watch 1.42 more hours of tv, on average, than respondents who identify as ‚ÄúOther‚Äù. White respondents watch .009 more hours of tv, on average, than respondents who identify as ‚ÄúOther‚Äù. Respondents who identify as ‚ÄúOther‚Äù watch, on average, 2.76 hours of TV. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5a799cb8b29514f4858bf9f7ce618eee","permalink":"/class/regression/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/regression/","section":"class","summary":"In-class example Drawing lines (geom_smooth) ggcorrplot Draw the line Convince yourself IR Econ In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù\nday1-models.R day2-models.R Drawing lines (geom_smooth) Why draw trend lines? Trend lines give us a good, educated guess as to what the value of a Y variable is given some value of X.","tags":null,"title":"Correlation and regression","type":"docs"},{"authors":null,"categories":null,"content":"Instructions Download this: ps-causality right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a5f459de4b46ad58b344355b2d6ab8d5","permalink":"/assignment/ps-dags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/ps-dags/","section":"assignment","summary":"Instructions Download this: ps-causality right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","tags":null,"title":"DAGs","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Making DAGs with ggdag() In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nday1-dags.R day2-dags.R Making DAGs with ggdag() To make DAGs we use dagify() from the ggdag package. Note the basic format:\nY ~ A + B + C + ‚Ä¶ = think of this as ‚ÄúY is caused by A, B, C, ‚Ä¶‚Äù. you need to specify the treatment variable with exposure (another word for ‚Äútreatment‚Äù) and the outcome variable with outcome library(ggdag) library(tidyverse) # make a dag dag = dagify(Y ~ X + A + B + C, X ~ A, A ~ B + C, exposure = \u0026quot;X\u0026quot;, outcome = \u0026quot;Y\u0026quot;) We can then plot with ggdag:\n# plot it ggdag(dag) We can make prettier in the following ways (but no need):\nggdag(dag) + theme_dag() We can use ggdag_paths to identify front and backdoor paths from treatment to outcome:\nggdag_paths(dag) We can use ggdag_adjustment_set to see what variables we need to control for:\nggdag_adjustment_set(dag) We can also use words instead of letters:\n## made up exqmple: shuttle service --\u0026gt; turnout dag = dagify(turnout ~ shuttle + income + distance_poll + schedule_flex, income ~ job + location, distance_poll ~ location + car, shuttle ~ cost + partisan + location, exposure = \u0026quot;shuttle\u0026quot;, outcome = \u0026quot;turnout\u0026quot;) If we want to use labels instead of text to make it easier to read:\nggdag(dag, use_labels = \u0026quot;name\u0026quot;, text = FALSE) + theme_dag() ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8c6e21291818c37bba3d07ce54d63f30","permalink":"/class/dags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/dags/","section":"class","summary":"In-class example Making DAGs with ggdag() In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nday1-dags.R day2-dags.R Making DAGs with ggdag() To make DAGs we use dagify() from the ggdag package. Note the basic format:\nY ~ A + B + C + ‚Ä¶ = think of this as ‚ÄúY is caused by A, B, C, ‚Ä¶‚Äù.","tags":null,"title":"DAGs","type":"docs"},{"authors":null,"categories":null,"content":" Recommended Slides Tuesday Thursday Recommended work through the examples in the ggdag package vignette here.1\nDirected Acyclical Graphs in Causal Inference: The Mixtape2\nSlides Tuesday Class slides here\nThursday Class slides here\nDon‚Äôt just copy/paste the code; write it out yourself! Change the variables in the smoking/cancer example to something of interest to you.‚Ü©Ô∏é\nThis reading is mathy-er than what we‚Äôve covered so far. It also features code from STATA, which we don‚Äôt use. Don‚Äôt worry about that so much; we will focus on broad concepts/ideas.‚Ü©Ô∏é\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b61171b32a3df738ee3e8b1353530cf5","permalink":"/reading/08-dags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/08-dags/","section":"reading","summary":"Recommended Slides Tuesday Thursday Recommended work through the examples in the ggdag package vignette here.1\nDirected Acyclical Graphs in Causal Inference: The Mixtape2\nSlides Tuesday Class slides here\nThursday Class slides here\nDon‚Äôt just copy/paste the code; write it out yourself! Change the variables in the smoking/cancer example to something of interest to you.‚Ü©Ô∏é\nThis reading is mathy-er than what we‚Äôve covered so far. It also features code from STATA, which we don‚Äôt use.","tags":null,"title":"DAGs","type":"docs"},{"authors":null,"categories":null,"content":"Instructions Download this: ps-summary right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"82a5ed23c401cb990cce068f82330db6","permalink":"/assignment/ps-summary/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/ps-summary/","section":"assignment","summary":"Instructions Download this: ps-summary right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","tags":null,"title":"Data summaries","type":"docs"},{"authors":null,"categories":null,"content":"Instructions Download this: ps-viz right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"99214408639ad410c2432d58d0197c2a","permalink":"/assignment/ps-viz/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/ps-viz/","section":"assignment","summary":"Instructions Download this: ps-viz right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","tags":null,"title":"Data visualization","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Making graphs with ggplot The scatterplot The time series Multiple time series Histogram with geom_histogram() Grouped histogram Barplot with geom_col() The boxplot Other layers and features Multi-panel plots with facet_wrap() Make aesthetics static within the geometries Show a trend-line using geom_smooth() Show separate trend-lines Use different color and fill scales Many other themes In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nDay one: Five graphs Day two: Day 2 Making graphs with ggplot Here we will walk through how to make some of the basic graphs in R.\nThe code chunk below loads our libraries and prepares the data.\n# load libraries ------------------------------------------------------------------------- library(tidyverse) library(gapminder) # install this if you don\u0026#39;t have it! library(ggbeeswarm) # install this if you don\u0026#39;t have it! library(moderndive) # clean data ------------------------------------------------------------------------ # subset data to focus on 2007 gap_07 = gapminder %\u0026gt;% filter(year == 2007) # calculate average life span by year life_yr = gapminder %\u0026gt;% select(year, lifeExp) %\u0026gt;% group_by(year) %\u0026gt;% summarise(avg_yrs = mean(lifeExp)) # calculate average life expectancy by continent life_region = gap_07 %\u0026gt;% group_by(continent) %\u0026gt;% summarise(avg_yrs = mean(lifeExp)) # calculate average life expectancy by continent-year life_region_yr = gapminder %\u0026gt;% group_by(continent, year) %\u0026gt;% summarise(avg_yrs = mean(lifeExp)) The scatterplot The scatterplot puts two variables on the same graph so we can see how they move together:\n# the fancy, final product ggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) + geom_point() We can add labels using labs() and a theme using theme_bw():\nggplot(gap_07, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) + geom_point() + labs(x = \u0026quot;GDP per capita ($USD, inflation-adjusted)\u0026quot;, y = \u0026quot;Life expectancy (in years)\u0026quot;, title = \u0026quot;Wealth and Health Around the World\u0026quot;, subtitle = \u0026quot;Data from 2007. Source: gapminder package.\u0026quot;) + theme_bw() Note that there are many more themes out there.\nThe time series The time series shows you how a variable moves over time, using a line. For this one we will use the life_yr data object we constructed above, which looks like this:\n## look at the data life_yr ## # A tibble: 12 √ó 2 ## year avg_yrs ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1952 49.1 ## 2 1957 51.5 ## 3 1962 53.6 ## 4 1967 55.7 ## 5 1972 57.6 ## 6 1977 59.6 ## 7 1982 61.5 ## 8 1987 63.2 ## 9 1992 64.2 ## 10 1997 65.0 ## 11 2002 65.7 ## 12 2007 67.0 We make the plot below:\n# make the plot ggplot(life_yr, aes(x = year, y = avg_yrs)) + geom_line() + theme_bw() Multiple time series Sometimes we have data where we observe multiple units moving over time, like so:\nlife_region_yr ## # A tibble: 60 √ó 3 ## # Groups: continent [5] ## continent year avg_yrs ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Africa 1952 39.1 ## 2 Africa 1957 41.3 ## 3 Africa 1962 43.3 ## 4 Africa 1967 45.3 ## 5 Africa 1972 47.5 ## 6 Africa 1977 49.6 ## 7 Africa 1982 51.6 ## 8 Africa 1987 53.3 ## 9 Africa 1992 53.6 ## 10 Africa 1997 53.6 ## # ‚Ä¶ with 50 more rows We can draw separate time series for each unit by either using the color aesthetic to separate the lines:\nggplot(life_region_yr, aes(x = year, y = avg_yrs, color = continent)) + geom_line() + theme_bw() Or the group aesthetic:\nggplot(life_region_yr, aes(x = year, y = avg_yrs, group = continent)) + geom_line() + theme_bw() Histogram with geom_histogram() ggplot(gap_07, aes(x = lifeExp)) + geom_histogram() + theme_bw() Grouped histogram ggplot(gap_07, aes(x = lifeExp, fill = continent)) + geom_histogram() + theme_bw() Barplot with geom_col() ggplot(life_region_yr, aes(x = continent, y = avg_yrs)) + geom_col() The boxplot ggplot(data = gapminder, aes(x = continent, y = lifeExp)) + geom_boxplot() Other layers and features Multi-panel plots with facet_wrap() ggplot(gapminder, aes(x = lifeExp, fill = continent)) + geom_histogram() + facet_wrap(vars(year)) + theme_minimal() Make aesthetics static within the geometries ggplot(gap_07, aes(x = gdpPercap, y = lifeExp)) + theme_light() + geom_point(size = 3, color = \u0026quot;orange\u0026quot;, shape = 2, alpha = .5) #\u0026lt;\u0026lt; Take your aesthetics out of aes() and into geom() to make them static\nShow a trend-line using geom_smooth() ggplot(evals, aes(x = age, y = score)) + geom_point() + theme_bw() + labs(x = \u0026quot;Professor age\u0026quot;, y = \u0026quot;Student evals\u0026quot;) + geom_smooth() #\u0026lt;\u0026lt; Trend lines can reveal patterns in ‚Äúclumpy‚Äù data\nShow separate trend-lines ggplot(evals, aes(x = age, y = score, color = gender)) + #\u0026lt;\u0026lt; geom_point() + theme_bw() + labs(x = \u0026quot;Professor age\u0026quot;, y = \u0026quot;Student evals\u0026quot;) + geom_smooth() #\u0026lt;\u0026lt; Relationships can look different within groups\nUse different color and fill scales ggplot(gapminder, aes(x = lifeExp, fill = continent)) + geom_histogram() + scale_fill_brewer(palette = \u0026quot;Blues\u0026quot;) #\u0026lt;\u0026lt; fill_brewer() for fill, color_brewer for color\nMany other themes library(tvthemes) ggplot(gapminder, aes(x = lifeExp, fill = continent)) + geom_histogram() + theme_spongeBob() + labs(title = \u0026quot;Horrible\u0026quot;) + scale_fill_spongeBob() theme_spongeBob() from tvthemes package, many more online\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c62f7bd1cd2cf1ee3426f2c188f05679","permalink":"/class/dataviz/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/dataviz/","section":"class","summary":"In-class example Making graphs with ggplot The scatterplot The time series Multiple time series Histogram with geom_histogram() Grouped histogram Barplot with geom_col() The boxplot Other layers and features Multi-panel plots with facet_wrap() Make aesthetics static within the geometries Show a trend-line using geom_smooth() Show separate trend-lines Use different color and fill scales Many other themes In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course.","tags":null,"title":"Data visualization","type":"docs"},{"authors":null,"categories":null,"content":"Instructions Download this: ps-wrangle right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a4978dfab1e13a08a07e687e0ad6eb11","permalink":"/assignment/ps-wrangle/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/ps-wrangle/","section":"assignment","summary":"Instructions Download this: ps-wrangle right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","tags":null,"title":"Data wrangling","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Filtering Examples Leaders Mutating Creating categorical variables In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù\nwrangle-day1.R\nFiltering Often, we have a big dataset that covers lots of stuff (say, all flights coming out of NYC in 2013) but we‚Äôre only interested in a subset of those things (say, flights that arrived late over that time period). The filter() function is a way to subset operations that match some rule or set of rules (e.g., rule = ‚Äúflights that arrived late‚Äù). We define these rules using logical operators.\nExamples Let‚Äôs load the libraries.\n# libraries library(tidyverse) library(nycflights13) Remember you can look at the data like this.\n# look at the data View(flights) # open data in viewer ?flights # read data documentation Let‚Äôs look at flights from February.\n# look at fights, but only from February flights %\u0026gt;% filter(month == 2) ## # A tibble: 24,951 √ó 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 2013 2 1 456 500 -4 652 648 ## 2 2013 2 1 520 525 -5 816 820 ## 3 2013 2 1 527 530 -3 837 829 ## 4 2013 2 1 532 540 -8 1007 1017 ## 5 2013 2 1 540 540 0 859 850 ## 6 2013 2 1 552 600 -8 714 715 ## 7 2013 2 1 552 600 -8 919 910 ## 8 2013 2 1 552 600 -8 655 709 ## 9 2013 2 1 553 600 -7 833 815 ## 10 2013 2 1 553 600 -7 821 825 ## # ‚Ä¶ with 24,941 more rows, and 11 more variables: arr_delay \u0026lt;dbl\u0026gt;, ## # carrier \u0026lt;chr\u0026gt;, flight \u0026lt;int\u0026gt;, tailnum \u0026lt;chr\u0026gt;, origin \u0026lt;chr\u0026gt;, dest \u0026lt;chr\u0026gt;, ## # air_time \u0026lt;dbl\u0026gt;, distance \u0026lt;dbl\u0026gt;, hour \u0026lt;dbl\u0026gt;, minute \u0026lt;dbl\u0026gt;, time_hour \u0026lt;dttm\u0026gt; Let‚Äôs look at flights on Valentine‚Äôs Day.\n# now let\u0026#39;s look at flights on Valentine\u0026#39;s Day flights %\u0026gt;% filter(month == 2) %\u0026gt;% filter(day == 14) ## # A tibble: 956 √ó 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 2013 2 14 7 2352 15 448 437 ## 2 2013 2 14 59 2339 80 205 106 ## 3 2013 2 14 454 500 -6 641 648 ## 4 2013 2 14 510 515 -5 750 814 ## 5 2013 2 14 531 530 1 828 831 ## 6 2013 2 14 541 540 1 850 850 ## 7 2013 2 14 542 545 -3 1014 1023 ## 8 2013 2 14 551 600 -9 831 906 ## 9 2013 2 14 552 600 -8 657 708 ## 10 2013 2 14 553 600 -7 902 856 ## # ‚Ä¶ with 946 more rows, and 11 more variables: arr_delay \u0026lt;dbl\u0026gt;, carrier \u0026lt;chr\u0026gt;, ## # flight \u0026lt;int\u0026gt;, tailnum \u0026lt;chr\u0026gt;, origin \u0026lt;chr\u0026gt;, dest \u0026lt;chr\u0026gt;, air_time \u0026lt;dbl\u0026gt;, ## # distance \u0026lt;dbl\u0026gt;, hour \u0026lt;dbl\u0026gt;, minute \u0026lt;dbl\u0026gt;, time_hour \u0026lt;dttm\u0026gt; Let‚Äôs try the OR logical operator by looking at flights going to ATL or SFO.\n# try one using text and the OR symbol # look at fights going to ATL or SFO flights %\u0026gt;% filter(dest == \u0026quot;ATL\u0026quot; | dest == \u0026quot;SFO\u0026quot;) ## # A tibble: 30,546 √ó 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 2013 1 1 554 600 -6 812 837 ## 2 2013 1 1 558 600 -2 923 937 ## 3 2013 1 1 600 600 0 837 825 ## 4 2013 1 1 606 610 -4 837 845 ## 5 2013 1 1 611 600 11 945 931 ## 6 2013 1 1 615 615 0 833 842 ## 7 2013 1 1 655 700 -5 1037 1045 ## 8 2013 1 1 658 700 -2 944 939 ## 9 2013 1 1 729 730 -1 1049 1115 ## 10 2013 1 1 734 737 -3 1047 1113 ## # ‚Ä¶ with 30,536 more rows, and 11 more variables: arr_delay \u0026lt;dbl\u0026gt;, ## # carrier \u0026lt;chr\u0026gt;, flight \u0026lt;int\u0026gt;, tailnum \u0026lt;chr\u0026gt;, origin \u0026lt;chr\u0026gt;, dest \u0026lt;chr\u0026gt;, ## # air_time \u0026lt;dbl\u0026gt;, distance \u0026lt;dbl\u0026gt;, hour \u0026lt;dbl\u0026gt;, minute \u0026lt;dbl\u0026gt;, time_hour \u0026lt;dttm\u0026gt; Let‚Äôs look at flights between noon and 5pm.\n# try one using greater than or less than # look at flights departing between 12pm and 5pm flights %\u0026gt;% filter(dep_time \u0026gt;= 1200) %\u0026gt;% filter(dep_time \u0026lt;= 1700) ## # A tibble: 99,136 √ó 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 2013 1 1 1200 1200 0 1408 1356 ## 2 2013 1 1 1202 1207 -5 1318 1314 ## 3 2013 1 1 1202 1159 3 1645 1653 ## 4 2013 1 1 1203 1205 -2 1501 1437 ## 5 2013 1 1 1203 1200 3 1519 1545 ## 6 2013 1 1 1204 1200 4 1500 1448 ## 7 2013 1 1 1205 1200 5 1503 1505 ## 8 2013 1 1 1206 1209 -3 1325 1328 ## 9 2013 1 1 1208 1158 10 1540 1502 ## 10 2013 1 1 1211 1215 -4 1423 1413 ## # ‚Ä¶ with 99,126 more rows, and 11 more variables: arr_delay \u0026lt;dbl\u0026gt;, ## # carrier \u0026lt;chr\u0026gt;, flight \u0026lt;int\u0026gt;, tailnum \u0026lt;chr\u0026gt;, origin \u0026lt;chr\u0026gt;, dest \u0026lt;chr\u0026gt;, ## # air_time \u0026lt;dbl\u0026gt;, distance \u0026lt;dbl\u0026gt;, hour \u0026lt;dbl\u0026gt;, minute \u0026lt;dbl\u0026gt;, time_hour \u0026lt;dttm\u0026gt; Let‚Äôs look at how many flights arrived late on christmas day.\n## how many flights arrived LATE, on christmas day? late_xmas = flights %\u0026gt;% filter(arr_time \u0026gt; sched_arr_time) %\u0026gt;% filter(month == 12, day == 25) Leaders library(juanr) leader ## # A tibble: 17,686 √ó 16 ## country gwcode leader gender year yr_office age edu mil_service combat ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 USA 2 Grant M 1869 1 47 Univer‚Ä¶ 1 1 ## 2 USA 2 Grant M 1870 2 48 Univer‚Ä¶ 1 1 ## 3 USA 2 Grant M 1871 3 49 Univer‚Ä¶ 1 1 ## 4 USA 2 Grant M 1872 4 50 Univer‚Ä¶ 1 1 ## 5 USA 2 Grant M 1873 5 51 Univer‚Ä¶ 1 1 ## 6 USA 2 Grant M 1874 6 52 Univer‚Ä¶ 1 1 ## 7 USA 2 Grant M 1875 7 53 Univer‚Ä¶ 1 1 ## 8 USA 2 Grant M 1876 8 54 Univer‚Ä¶ 1 1 ## 9 USA 2 Grant M 1877 9 55 Univer‚Ä¶ 1 1 ## 10 USA 2 Hayes M 1877 1 55 Gradua‚Ä¶ 1 1 ## # ‚Ä¶ with 17,676 more rows, and 6 more variables: rebel \u0026lt;dbl\u0026gt;, yrs_exp \u0026lt;dbl\u0026gt;, ## # phys_health \u0026lt;dbl\u0026gt;, mental_health \u0026lt;dbl\u0026gt;, will_force \u0026lt;dbl\u0026gt;, ## # will_force_sd \u0026lt;dbl\u0026gt; A Vietnamese Emperor who, in his first year in office, was 11 years old. Famously depraved. leader %\u0026gt;% # first year in office filter(yr_office == 1) %\u0026gt;% # age at that point filter(age == 11) %\u0026gt;% # vietnamese filter(country == \u0026quot;VNM\u0026quot;) ## # A tibble: 1 √ó 16 ## country gwcode leader gender year yr_office age edu mil_service combat ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 VNM 815 Thanh T‚Ä¶ M 1889 1 11 Secon‚Ä¶ 0 0 ## # ‚Ä¶ with 6 more variables: rebel \u0026lt;dbl\u0026gt;, yrs_exp \u0026lt;dbl\u0026gt;, phys_health \u0026lt;dbl\u0026gt;, ## # mental_health \u0026lt;dbl\u0026gt;, will_force \u0026lt;dbl\u0026gt;, will_force_sd \u0026lt;dbl\u0026gt; Leaders with graduate degrees who in 2015 reached their 16th year in power. leader %\u0026gt;% filter(edu == \u0026quot;Graduate\u0026quot;, yr_office == 16, year == 2015) ## # A tibble: 2 √ó 16 ## country gwcode leader gender year yr_office age edu mil_service combat ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 RUS 365 Putin M 2015 16 63 Grad‚Ä¶ 0 0 ## 2 SYR 652 Bashar a‚Ä¶ M 2015 16 50 Grad‚Ä¶ 1 0 ## # ‚Ä¶ with 6 more variables: rebel \u0026lt;dbl\u0026gt;, yrs_exp \u0026lt;dbl\u0026gt;, phys_health \u0026lt;dbl\u0026gt;, ## # mental_health \u0026lt;dbl\u0026gt;, will_force \u0026lt;dbl\u0026gt;, will_force_sd \u0026lt;dbl\u0026gt; The number of world leaders in the post-2000 period who have known physical or mental health issues. leader %\u0026gt;% filter((year \u0026gt; 2000) \u0026amp; (phys_health == 1 | mental_health == 1)) ## # A tibble: 103 √ó 16 ## country gwcode leader gender year yr_office age edu mil_service combat ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 CAN 20 Chreti‚Ä¶ M 2001 9 62 Unive‚Ä¶ 0 0 ## 2 CAN 20 Chreti‚Ä¶ M 2002 10 63 Unive‚Ä¶ 0 0 ## 3 CAN 20 Chreti‚Ä¶ M 2003 11 64 Unive‚Ä¶ 0 0 ## 4 SLV 349 Drnovs‚Ä¶ M 2001 2 51 Gradu‚Ä¶ 0 0 ## 5 SLV 349 Drnovs‚Ä¶ M 2002 3 52 Gradu‚Ä¶ 0 0 ## 6 BLR 370 Lukash‚Ä¶ M 2001 8 47 Gradu‚Ä¶ 1 0 ## 7 BLR 370 Lukash‚Ä¶ M 2002 9 48 Gradu‚Ä¶ 1 0 ## 8 BLR 370 Lukash‚Ä¶ M 2003 10 49 Gradu‚Ä¶ 1 0 ## 9 BLR 370 Lukash‚Ä¶ M 2004 11 50 Gradu‚Ä¶ 1 0 ## 10 BLR 370 Lukash‚Ä¶ M 2005 12 51 Gradu‚Ä¶ 1 0 ## # ‚Ä¶ with 93 more rows, and 6 more variables: rebel \u0026lt;dbl\u0026gt;, yrs_exp \u0026lt;dbl\u0026gt;, ## # phys_health \u0026lt;dbl\u0026gt;, mental_health \u0026lt;dbl\u0026gt;, will_force \u0026lt;dbl\u0026gt;, ## # will_force_sd \u0026lt;dbl\u0026gt; Mutating Sometimes we want to create new variables. For example, we might want to combine or alter existing variables in our dataset. The mutate() function is one way of doing this.\nLet‚Äôs convert arrival delay from minutes to hours.\n## convert arrival_delay to hours new_flights = flights %\u0026gt;% mutate(arr_delay_hrs = arr_delay/60) If you look in the dataset you will see a new variable called arr_delay_hrs.\nLet‚Äôs convert distance traveled from miles to thousands of miles.\n## convert distance to thousands of miles new_flights2 = flights %\u0026gt;% mutate(dist_miles = distance/1000) Creating categorical variables Sometimes we want to create more complicated variables. Here‚Äôs where case_when comes into play.\nLet‚Äôs create a variable that tells us what season a flight took off in.\n## create a new variable called season ## that tells me if flight departed ## in summer, winter, fall, or spring new_flights = flights %\u0026gt;% mutate(seasons = case_when(month == 6 ~ \u0026quot;Summer\u0026quot;, month == 7 ~ \u0026quot;Summer\u0026quot;, month == 8 ~ \u0026quot;Summer\u0026quot;, month == 9 ~ \u0026quot;Fall\u0026quot;, month == 10 ~ \u0026quot;Fall\u0026quot;, month == 11 ~ \u0026quot;Fall\u0026quot;, month == 12 ~ \u0026quot;Winter\u0026quot;, month == 1 ~ \u0026quot;Winter\u0026quot;, month == 2 ~ \u0026quot;Winter\u0026quot;, month == 3 ~ \u0026quot;Spring\u0026quot;, month == 4 ~ \u0026quot;Spring\u0026quot;, month == 5 ~ \u0026quot;Spring\u0026quot;)) We can then plot the distribution of arrival delays by season, below.\n# plot histogram of arrival delay # separate it by season ggplot(new_flights, aes(x = arr_delay, fill = seasons)) + geom_histogram() + facet_wrap(vars(seasons)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 9430 rows containing non-finite values (stat_bin). Let‚Äôs say we wanted to categorize flights by how late they are. See an example, below.\nnew_flights = flights %\u0026gt;% mutate(time_flight = case_when(arr_delay \u0026gt;= 120 ~ \u0026quot;very late\u0026quot;, arr_delay \u0026gt; 0 \u0026amp; arr_delay \u0026lt; 120 ~ \u0026quot;a little late\u0026quot;, arr_delay == 0 ~ \u0026quot;on time\u0026quot;, arr_delay \u0026lt; 0 \u0026amp; arr_delay \u0026gt; -120 ~ \u0026quot;a little early\u0026quot;, arr_delay \u0026lt;=-120 ~ \u0026quot;very early\u0026quot;)) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"231b0fb6b1b67cb2a41cb4dd7f11e4a4","permalink":"/class/data-wrangle/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/data-wrangle/","section":"class","summary":"In-class example Filtering Examples Leaders Mutating Creating categorical variables In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù\nwrangle-day1.R\nFiltering Often, we have a big dataset that covers lots of stuff (say, all flights coming out of NYC in 2013) but we‚Äôre only interested in a subset of those things (say, flights that arrived late over that time period).","tags":null,"title":"Data Wrangling","type":"docs"},{"authors":null,"categories":null,"content":" Required Required Pages 263 through 287 in Scott Cunningham‚Äôs The Causal Mixtape\nWatch this video on estimating the effects of migration on employment, using a diff-in-diff design\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5d1e013da2770e88750c489f6526effc","permalink":"/reading/did/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/did/","section":"reading","summary":"Required Required Pages 263 through 287 in Scott Cunningham‚Äôs The Causal Mixtape\nWatch this video on estimating the effects of migration on employment, using a diff-in-diff design","tags":null,"title":"Difference-in-difference","type":"docs"},{"authors":null,"categories":null,"content":" Instructions Your primary goal is this: to explore the effect of some treatment on an outcome you are interested in, using one of the datasets below. You get to decide what the treatment and outcome variable are; there is more than one \u0026ldquo;right\u0026rdquo; answer. I provide a few ideas beneath each dataset but you can do what you want.\nBrowse through the different topics, think about what causal story you want to tell, and pick the topic you want. Download the adjoining Rmarkdown template, and complete the following activities outlined there.\nYou can use your notes, slides, and any other material from the course, but you must work on this independently.\nOnce you are done, you will submit the completed .Rmd file on Canvas. Late submissions will not be accepted.\nHelp from instructors On the problem sets the instructors (the professor + TAs) provided substantial guidance. This is not the case for the final project. We will not provide any help in answering questions. This is your chance to show how much you have learned.\nIf there are MAJOR issues that prevent you from working on the project (e.g., you cannot load the dataset at the top of the Rmd file), reach out to us ASAP, by email. If there are clarification questions about the language of a question, also reach out to us ASAP by email.\nEvaluation Your project will be evaluated along two dimensions:\naccuracy (90% of grade): did you answer the questions well? does your code work? did you interpret the results correctly? is your argument clear and persuasive? Basically: how good is your project? professionalism (10% of grade): is it neat, organized, easy to read? is your writing grammatical, uses capitalization, punctuation, etc.? are graphs neat and well-labeled? Basically: how presentable is your project? Note If you need more information about the data, a specific variable, etc., look through the linked articles or codebooks.\nDataset options War, gender, and social change One of the big changes that World War II brought about in the US was the entrance of women into the labor force in massive numbers. Over this period, involvement of women in economic and political life also increased dramatically.\nWars are big, destabilizing events that can dramatically transform societies. Can wars, either domestic or foreign, change gender relations within a country?\nThis dataset comes from this IO article by Webster, Chen, and Beardsley and includes information on women\u0026rsquo;s involvement in civil society and politics, war, and other related variables, using data from every country between 1900 and 2015.\nvariable meaning year Year country_name Country name polempowerment Measure of women's political empowerment in the country in that year, from VDEM (variable: V2x_GENDER). Ranges from 0 (low) to 1 (high). civilsoci Measure of how active women are in civil society, from VDEM (variable: V2X_GENCS). Ranges from 0 (low) to 1 (high) fertility Women's fertility rates (average number of births per woman) inter_war Did an international war take place? (1 = yes, 0 = no). intra_war Did a civil war take place? (1 = yes, 0 = no). milper Military personnel per capita milex_pc Military expenditures per capita population Total population polity2 Country's democracy score in that year, from POLITY2. Ranging from full autocracy (-10) to full democracy (10). Ideas:\neffects of civil war on women\u0026rsquo;s empowerment effects of international war on women\u0026rsquo;s empowerment effects of war on fertility effect of democratization on military spending The template Webster template\nWestern education and the spread of democracy Despite living in autocratic countries, dictators often either attend or send their kids to universities in democratic countries where some of the world\u0026rsquo;s top universities are often located. Does the experience of living in a democratic state influence leaders once they return? Could experiences like this \u0026ldquo;spread\u0026rdquo; democracy?\nThis dataset comes from a JCR study by Gift and Krcmaric. The dataset contains information on world leaders, where they were educated, how democracy changed in their countries during their tenure, and other factors.\nvariable meaning leader Name of the leader startdate When the leader started their tenure enddate When the leader ended their tenure angloedu Was leader educated in an English-speaking country? westedu Was leader educated in the West? noedu Did leader have no higher education? polity2change Change in POLITY2 score over leader's tenure (positive = country became more democratic, negative = less democratic) BMRtransition 1 if country underwent democratic transition ethfrac Ethnic fractionalization index of country britcolony Is leader in a former british colony? igdp interpolated real GDP per capita /100,000 usally did country have cold war alliance with USA at any point? ioil does the country have oil? ipolconiii Executive constraints variable (from 0 to 1) studentflowthousand students studying in the US (in thousands) Ideas:\ndoes a leader receiving a Western education spread democracy to their home countries? does a leader receiving a Western education make alliances with the US more likely? does a leader having lots of students studying abroad in the US make US alliances more likely? does a country experiencing a democratic transition increase the likelihood a leader studies in the West? or that more of their students study in the West? The template Gift template\nThe effects of criminal victimization Many people in the world become victims of crime at some point or another in their lives. These experiences can be highly traumatic. How does criminal victimization change people and their attitudes and beliefs? Do they become more conservative, or liberal? Do they become more supportive of harsh policies? Or do they become more involved in their communities, and seek change?\nThis dataset comes from LAPOP, and the codebook. The data is a survey of people living across a dozen countries in Latin America, their experiences with crime, their attitudes towards democracy, how they think the state should respond to crime, and so on.\nvariable meaning country Country sex Sex age Age education Years of education ethnicity Ethnicity vigilante Approval of Vigilante Justice (1 = none, 10 = a lot) income Income victim Victim of a crime in last 12 months coup_support Agrees that a military coup is justified if crime is high neighbor_crime Murders have taken place in neighborhood attend_meeting Did respondent attend community meeting? protested Did respondent participate in a protest? solve_problems How often respondent helps solve local problem (1, Once a week, 2 = Once or twice a month, 3 = Once or twice a year, 4 = Never) ideology Ideology (1 = far left, 10 = far right) Ideas:\ndoes being a victim of a crime increase support for military coups or vigilante justice? can education reduce support for military coups? does being a victim of crime make someone more ideologically conservative? do victims of crime become more involved in their communities, or engage in protest? does the experience of participating in a protest make someone become more liberal or conservative? The template LAPOP template\nJudicial appointments and public opinion in the US The appointment and confirmation of judges to the Supreme Court is an increasingly important and politicized process. Do politicians, in voting to confirm a Supreme Court nominee, respond to public pressure? Or do they act more autonomously?\nThis dataset comes from a JOP article by Kastellec, Lax, and Phillips. The dataset contains estimates of public support for the confirmation of 10 recent Supreme Court nominees, how Senators voted during the confirmation process, and other factors, in all 50 states.\nvariable meaning nominee Name of the nominated judge state State year Year congress Congressional number name Name of Senator democrat Whether Senator is a Democrat senator_ideology Senator's ideology, on a -1 (liberal) to +1 (conservative) scale vote if the senator voted to confirm the nominee pres.dem if the nominating president was a Democrat sameprty if the senator is the same party as the president nom_ideology Nominee's ideology, on a 0 (conservative) to 1 (liberal) scale opinion nominee's approval rating (out of 100%) in the senator's state at the time of the vote reelection if the senator faces reelection within two years of the vote Ideas:\ndoes public support for a Supreme Court nominee cause a Senator to vote for that candidate? does not having to face reelection change how Senators vote? does a senator\u0026rsquo;s ideology cause them to vote in particular ways during Senate confirmations? The template Kastellec template\nWelfare and race in the United States There\u0026rsquo;s a big literature on how debates over redistributive policy (e.g., welfare measures) in the United States can often become racialized \u0026ndash; that people support or oppose welfare policies not on the merits but rather on which groups they anticipate will benefit from such policies and their attitudes towards those groups.\nThis data comes from the 2019 Democracy Fund Voter Study Group, codebook here. The data is a survey of Americans, and includes information on racial prejudice, demographics, ideology, and support for welfare policies.\nvariable meaning state State birth_year Year born sex Sex race Race party_id Party identification ideo5_2019 Ideology (1 = very liberal, 5 = very conservative) newsint_2019 Interested in politics (1 = most of the time, 4 = hardly at all) pew_religimp_2019 Importance of religion (1 = very important, 4 = not all important) faminc_new_2019 Check codebook educ_2019 Check codebook ft_black_2017 Feeling thermometer, Blacks (0 = strong dislike, 100 = strong like) ft_hisp_2017 Feeling thermometer, Hispanics (0 = strong dislike, 100 = strong like) ft_asian_2017 Feeling thermometer, Asians (0 = strong dislike, 100 = strong like) diff_inc_2019 Government should redistribute wealth (1 = strongly agree, 5 = strongly disagree) Ideas:\ndoes racial prejudice cause changes in support for redistributive policies? does it depend on the group in question? can education reduce racial prejudice? does education cause people to become more liberal or more conservative? The template Prejudice template\nCoca and conflict in Colombia Colombia has one of the longest-running internal conflicts in the world, involving multiple armed groups over decades and also a thriving drug trade. Does past violence beget current violence? Does the drug trade cause conflict?\nThis data comes from The Center for Economic Development at the University of Los Andes, in Colombia, codebook here (in Spanish!)\nvariable meaning department Department muni Municipality year Year rural_pop Rural population urban_pop Urban population total_pop Total population area Area (km2) altitude Altitude (meters above sea level) discapital Distance to department capital la_violencia Dummy for violence during La Violencia (1948-1953) ocup_espan Dummy for Spanish occupation from 1510 - 1561 land_conflicts Dummy for land conflicts, 1901-1931 homicides Total homicides coca_hectares Number of hectares of coca cultivations (less accurate) coca Dummy for coca presence (more accurate) farc_attacks Number of attacks by the FARC para_attacks Number of attacks by the AUC Ideas:\ndoes the coca trade cause conflict by one group or another, or general homicides? do past conflicts, either during La Violencia, or over land, cause current conflicts? how has the experience of Spanish colonization in some parts of the country but not others influenced contemporary outcomes? The template Colombia template\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8aa7f9fab930cf904df951e7fdfc2eef","permalink":"/assignment/final-project/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/final-project/","section":"assignment","summary":"Instructions Your primary goal is this: to explore the effect of some treatment on an outcome you are interested in, using one of the datasets below. You get to decide what the treatment and outcome variable are; there is more than one \u0026ldquo;right\u0026rdquo; answer. I provide a few ideas beneath each dataset but you can do what you want.\nBrowse through the different topics, think about what causal story you want to tell, and pick the topic you want.","tags":null,"title":"Final Project","type":"docs"},{"authors":null,"categories":null,"content":" Required Required Read this overview of fixed effects models ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a3b4e622ef39bf7187698e04f21530b9","permalink":"/reading/fixed-effects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/fixed-effects/","section":"reading","summary":" Required Required Read this overview of fixed effects models ","tags":null,"title":"Fixed effects","type":"docs"},{"authors":null,"categories":null,"content":" The fixed effects DAG Simulation to show how it works Diff-in-diff by hand Diff-in-diff with regression library(ggdag) library(tidyverse) library(broom) library(fixest) library(gapminder) # set seed set.seed(1990) The fixed effects DAG Say we wanted to estimate the effect of GDP on life expectancy, and had a DAG like the following:\ndagify(Life ~ GDP + Geography + Population + Pollution + WW2 + Equator, GDP ~ Geography + Population + Pollution + WW2 + Equator, exposure = \u0026quot;GDP\u0026quot;, outcome = \u0026quot;Life\u0026quot;) %\u0026gt;% ggdag_status(text = FALSE, use_labels = \u0026quot;name\u0026quot;) + theme_dag(legend.position = \u0026quot;none\u0026quot;) The key thing here is that some of these variables only vary across countries, but not within them. They are constant within the country. For example, a country‚Äôs distance from the equator is fixed. Same with whether or not they participated in WW2. Other variables also vary within country, like a country‚Äôs level of pollution (or population) which changes over time.\nThe insight is that we can think about all of the variables that are constant within country as a general ‚Äúcountry‚Äù backdoor. The ‚Äúcountry‚Äù backdoor is all of the differences between the countries in our data that are static or fixed. Pollution and population are not included because they also vary within country.\ndagify(Life ~ GDP + Country + Population + Pollution, GDP ~ Country + Population + Pollution, exposure = \u0026quot;GDP\u0026quot;, outcome = \u0026quot;Life\u0026quot;) %\u0026gt;% ggdag_status(text = FALSE, use_labels = \u0026quot;name\u0026quot;) + theme_dag(legend.position = \u0026quot;none\u0026quot;) We can use fixed effects to control for the ‚Äúcountry‚Äù backdoor, and implicitly, all variables that are static within countries.\nHere‚Äôs the naive regression, without country fixed effects:\n# naive m1 = lm(lifeExp ~ gdpPercap + pop, data = gapminder) tidy(m1) ## # A tibble: 3 x 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 5.36e+1 0.322 166. 0. ## 2 gdpPercap 7.68e-4 0.0000257 29.9 4.04e-158 ## 3 pop 9.73e-9 0.00000000238 4.08 4.72e- 5 Here‚Äôs the fixed effect regression, using the fixest package. The general template is: feols(Y ~ X1 + X2 + ... | UNIT, data = DATA)\n# naive m2 = feols(lifeExp ~ gdpPercap + pop | country, data = gapminder) tidy(m2) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 gdpPercap 0.000394 0.000177 2.22 0.0279 ## 2 pop 0.0000000620 0.0000000180 3.44 0.000776 Notice how the estimate on GDP changes with the addition of FE. Notice also that we still haven‚Äôt closed all the backdoors in our original DAG! Pollution is a backdoor, and varies within country, so the country fixed effect will not suffice. We need to control for it, but we have no data on it! This captures the broad takeaway of FE:\nFE help us close backdoors that are constant within the unit But we still need to control for confounds that vary within the unit (e.g., population, pollution) We can add those alongside FE (e.g., population) but sometimes we don‚Äôt have data on all confounds that vary within unit, so we‚Äôre not out of the woods (e.g., pollution) Simulation to show how it works We‚Äôre gonna make up some data to estimate effect of a teacher having an MA on their student‚Äôs test scores. The DAG looks like this:\n# draw the dag dag = dagify(score ~ teacher_ma + male + parent_income, teacher_ma ~ male + parent_income, exposure = \u0026quot;teacher_ma\u0026quot;, outcome = \u0026quot;score\u0026quot;) ggdag_status(dag, text = FALSE, use_labels = \u0026quot;name\u0026quot;) + theme_dag() Notice we have some backdoors that we need to control for:\nggdag_adjustment_set(dag) Let‚Äôs make up the data:\n# make up student data kids = tibble(student = c(\u0026quot;Joe\u0026quot;, \u0026quot;Jessica\u0026quot;, \u0026quot;Laia\u0026quot;, \u0026quot;Jeff\u0026quot;, \u0026quot;Martin\u0026quot;), male = sample(c(1, 0), size = 5, replace = TRUE), parent_income = rnorm(5)) fake = crossing(student = unique(kids$student), test = 1:50) %\u0026gt;% left_join(kids) %\u0026gt;% mutate(teacher_ma = 2*male + 3*parent_income + rnorm(250)) %\u0026gt;% mutate(score = 5*teacher_ma + -2*male + 5*parent_income + rnorm(250)) Notice above that the true effect of teacher_ma on score is 5.\nHere‚Äôs the (wrong) result when we don‚Äôt control for anything:\n# naive regression lm(score ~ teacher_ma, data = fake) %\u0026gt;% tidy() ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) -3.67 0.193 -19.0 2.36e- 50 ## 2 teacher_ma 7.01 0.0619 113. 1.44e-215 Here‚Äôs the (right) result when we control for all confounds:\n# correctly specify controls lm(score ~ teacher_ma + parent_income + male, data = fake) %\u0026gt;% tidy() ## # A tibble: 4 x 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) -0.145 0.132 -1.10 2.74e- 1 ## 2 teacher_ma 5.08 0.0646 78.6 2.55e-176 ## 3 parent_income 4.82 0.206 23.4 1.27e- 64 ## 4 male -1.91 0.235 -8.12 2.21e- 14 Here‚Äôs the (right) result when we use student FE:\n# use fixed effects to account for student-constant variables feols(score ~ teacher_ma | student, data = fake) %\u0026gt;% tidy() ## # A tibble: 1 x 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 teacher_ma 5.08 0.0365 139. 0.0000000160 Notice above how we get the right answer even without controlling for the parent_income and male backdoors. This is because we are implicitly controlling for them.\nDiff-in-diff by hand Remember in class we were looking at the effect of Pokemon Go on exercise using difference-in-differences. Let‚Äôs see how this works by making up some data where we already know the effect of the app on exercise (let‚Äôs set the effect to 2).\nset.seed(1990) #Create our data fake_pokemon = tibble(year = sample(2002:2010,10000,replace=T), app = sample(c(\u0026quot;Has app\u0026quot;, \u0026quot;Doesn\u0026#39;t have app\u0026quot;), 10000, replace = TRUE)) %\u0026gt;% mutate(after = ifelse(year \u0026gt; 2007, 1, 0)) %\u0026gt;% mutate(D = after*(app == \u0026quot;Has app\u0026quot;)) %\u0026gt;% mutate(Y = 2*D + .25*year + (app == \u0026#39;Has app\u0026#39;) + rnorm(10000)) We can find that exact difference by filling out the 2x2 before/after treatment/control table:\nBefore 2016 After 2016 ‚àÜ Doesn‚Äôt have app A B B ‚àí A Has app C D D ‚àí C ‚àÜ C ‚àí A D ‚àí B (D ‚àí C) ‚àí (B ‚àí A) Here‚Äôs the table in our data:\n#Now, get before-after differences for both groups means = fake_pokemon %\u0026gt;% group_by(app,after) %\u0026gt;% summarize(Y=mean(Y)) means %\u0026gt;% pivot_wider(names_from = \u0026quot;after\u0026quot;, values_from = \u0026quot;Y\u0026quot;) %\u0026gt;% rename(After = `1`, Before = `0`) ## # A tibble: 2 x 3 ## # Groups: app [2] ## app Before After ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Doesn\u0026#39;t have app 501. 502. ## 2 Has app 502. 505. Let‚Äôs calculate all of the differences we need. Here‚Äôs B - A:\n502 - 501 ## [1] 1 This is the change in exercise in the pre to post-period among those who didn‚Äôt receive treatment (i.e., download the app). The exercise among these kids increased by 1. Why? Remember, all sorts of thing are happening in the world at any given time. And the app was released in summer! So this increase might just be because kids are out of school, or its nicer out, etc.\nLet‚Äôs calculate D - C:\n505 - 502 ## [1] 3 This is the change in exercise in the pre to post-period among those who did receive treatment (i.e., downloaded the app). The exercise among these kids increased by 3. Is this increase causal? No! Notice above that exercise also went up a bit among students who didn‚Äôt even have the app. So exercise went up over this time (because school‚Äôs out, it‚Äôs nice out, etc.). We need to remove this general increase in exercise. Let‚Äôs get the diff-in-diff estimate:\n(505 - 502) - (502 - 501) ## [1] 2 The diff-in-diff estimate is that exercise went up by 2 as a result of Pokemon Go.\nDiff-in-diff with regression We can also do diff-in-diff via regression (in fact this is how everyone does it). The basic template is: lm(Y ~ TREATMENT + TIME + TREATMENT*TIME, data = DATA)\nY is our outcome of interest (here: exercise) TREATMENT is a variable that tells us an observation‚Äôs treatment status (here: has pokemon go vs.¬†doesn‚Äôt have it) TIME is a variable that tells us if an observation is pre- or post-treatment (here: has pokemon go been released yet?) TREATMENT*TIME is the interaction of these two variables (more on this later) m1 = lm(Y ~ app + after + app*after, data = fake_pokemon) tidy(m1) ## # A tibble: 4 x 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 501. 0.0184 27233. 0. ## 2 appHas app 1.01 0.0259 39.0 1.44e-309 ## 3 after 1.13 0.0321 35.2 8.69e-256 ## 4 appHas app:after 1.99 0.0452 43.9 0. The coefficient for the interaction term (appHas app:after) is our diff-in-diff estimate. Here we would say that Pokemon Go increased the exercise rate by 2 among app users.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"692214d19057541b9aa07d98215c1460","permalink":"/class/fixed-effects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/fixed-effects/","section":"class","summary":"The fixed effects DAG Simulation to show how it works Diff-in-diff by hand Diff-in-diff with regression library(ggdag) library(tidyverse) library(broom) library(fixest) library(gapminder) # set seed set.seed(1990) The fixed effects DAG Say we wanted to estimate the effect of GDP on life expectancy, and had a DAG like the following:\ndagify(Life ~ GDP + Geography + Population + Pollution + WW2 + Equator, GDP ~ Geography + Population + Pollution + WW2 + Equator, exposure = \u0026quot;GDP\u0026quot;, outcome = \u0026quot;Life\u0026quot;) %\u0026gt;% ggdag_status(text = FALSE, use_labels = \u0026quot;name\u0026quot;) + theme_dag(legend.","tags":null,"title":"Fixed Effects + DID","type":"docs"},{"authors":null,"categories":null,"content":" Required Recommended Required Ch.4 in ModernDive\nCh.12 in R for Data Science\nRecommended Ch.11 in R for Data Science ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"34e23050487c78ee477bdb992e4f6234","permalink":"/reading/data-import/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/data-import/","section":"reading","summary":" Required Recommended Required Ch.4 in ModernDive\nCh.12 in R for Data Science\nRecommended Ch.11 in R for Data Science ","tags":null,"title":"Importing data","type":"docs"},{"authors":null,"categories":null,"content":" Required Required Ch.10 in ModernDive ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"402080419db456905f1cf035501ad139","permalink":"/reading/inference/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/inference/","section":"reading","summary":" Required Required Ch.10 in ModernDive ","tags":null,"title":"Inference for regression","type":"docs"},{"authors":null,"categories":null,"content":" Recommended Slides Tuesday Thursday Recommended CH.5 in ModernDive Slides Tuesday Class slides here\nThursday Class slides here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2f1977e0c28a115d3ffd96ddf1b6f62a","permalink":"/reading/05-reg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/05-reg/","section":"reading","summary":"Recommended Slides Tuesday Thursday Recommended CH.5 in ModernDive Slides Tuesday Class slides here\nThursday Class slides here","tags":null,"title":"Intro to regression","type":"docs"},{"authors":null,"categories":null,"content":"Instructions Download this: ps-models right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a44fcf9af8c2652fc4996b08e33012cd","permalink":"/assignment/ps-reg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/ps-reg/","section":"assignment","summary":"Instructions Download this: ps-models right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","tags":null,"title":"Models","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Closing backdoors with controls Dealing with forks Dealing with pipes Dealing with colliders In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nsocviz-maps.R\nClosing backdoors with controls library(ggdag) library(tidyverse) library(broom) # set seed set.seed(1990) Remember that one of the lessons from our week on DAGs is that in order to estimate the effect of X on Y, sometimes we need to control for some variables and avoid controlling for others.\nDealing with forks Here‚Äôs an example dealing with forks. The classic fork looks like this:\ndag = dagify(Y ~ Z, X ~ Z, exposure = \u0026quot;X\u0026quot;, outcome = \u0026quot;Y\u0026quot;) ggdag(dag) + theme_dag_blank() Notice that we need to control for Z:\nggdag_adjustment_set(dag) Let‚Äôs simulate some fake data from this DAG. Notice that X does not cause Y:\n# fake data fake = tibble(person = 1:200, z = rnorm(200), x = rnorm(200) + 2*z, y = rnorm(200) - 3*z) And yet when we look at X and Y there‚Äôs a relationship!\nggplot(fake, aes(x = x, y = y)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) We can see this relationship in regression too:\n# naive regression lm(y ~ x, data = fake) %\u0026gt;% tidy() ## # A tibble: 2 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 0.0655 0.125 0.523 6.01e- 1 ## 2 x -1.20 0.0524 -23.0 1.07e-57 But notice that when we correcty control for Z, the estimate on X goes to 0:\n# with controls lm(y ~ x + z, data = fake) %\u0026gt;% tidy() ## # A tibble: 3 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 0.0515 0.0741 0.694 4.88e- 1 ## 2 x -0.0245 0.0689 -0.356 7.22e- 1 ## 3 z -2.99 0.156 -19.1 7.53e-47 Dealing with pipes Here‚Äôs an example dealing with pipes The classic pipe looks like this:\ndag = dagify(Y ~ Z, Z ~ X, exposure = \u0026quot;X\u0026quot;, outcome = \u0026quot;Y\u0026quot;) ggdag(dag) + theme_dag_blank() Notice that we shouldn‚Äôt control for Z:\nggdag_adjustment_set(dag) Let‚Äôs simulate some fake data from this DAG. Notice that X -\u0026gt; Y -\u0026gt; Z:\n# fake data fake = tibble(person = 1:200, x = rnorm(200), z = rnorm(200) + 2*x, y = rnorm(200) - 3*z) When we look at X and Y, there‚Äôs a relationship:\nggplot(fake, aes(x = x, y = y)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) We can see this relationship in regression too:\nlm(y ~ x, data = fake) %\u0026gt;% tidy() ## # A tibble: 2 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 0.302 0.217 1.39 1.65e- 1 ## 2 x -6.17 0.235 -26.3 1.81e-66 But notice that when we incorrectly control for Z, the estimate on X goes to 0:\n# with controls lm(y ~ x + z, data = fake) %\u0026gt;% tidy() ## # A tibble: 3 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 0.00961 0.0698 0.138 8.91e- 1 ## 2 x -0.0667 0.164 -0.406 6.85e- 1 ## 3 z -2.99 0.0718 -41.7 1.03e-99 Dealing with colliders Here‚Äôs an example dealing with colliders The classic collider looks like this:\ndag = dagify(Z ~ Y + X, exposure = \u0026quot;X\u0026quot;, outcome = \u0026quot;Y\u0026quot;) ggdag(dag) + theme_dag_blank() Notice that we shouldn‚Äôt control for Z:\nggdag_adjustment_set(dag) Let‚Äôs simulate some fake data from this DAG. Notice that X does not cause Y:\n# fake data fake = tibble(person = 1:200, x = rnorm(200), y = rnorm(200), z = rnorm(200) + 2*x + -3*y) When we look at X and Y alone, there‚Äôs no relationship:\nggplot(fake, aes(x = x, y = y)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) We can see this relationship in regression too:\n# naive regression lm(y ~ x, data = fake) %\u0026gt;% tidy() ## # A tibble: 2 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) -0.0602 0.0765 -0.788 0.432 ## 2 x -0.0991 0.0738 -1.34 0.181 But notice that when we incorrectly control for Z, the estimate on X goes away from 0:\n# with controls lm(y ~ x + z, data = fake) %\u0026gt;% tidy() ## # A tibble: 3 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 0.00726 0.0235 0.309 7.58e- 1 ## 2 x 0.577 0.0274 21.1 2.62e- 52 ## 3 z -0.305 0.00698 -43.7 2.68e-103 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9183d5e4246c4cc67de690a5e11359ab","permalink":"/class/controls/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/controls/","section":"class","summary":"In-class example Closing backdoors with controls Dealing with forks Dealing with pipes Dealing with colliders In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nsocviz-maps.R\nClosing backdoors with controls library(ggdag) library(tidyverse) library(broom) # set seed set.seed(1990) Remember that one of the lessons from our week on DAGs is that in order to estimate the effect of X on Y, sometimes we need to control for some variables and avoid controlling for others.","tags":null,"title":"Natural Experiments","type":"docs"},{"authors":null,"categories":null,"content":" Recommended Slides Tuesday Thursday Recommended None\nSlides Tuesday Class slides here\nThursday Class slides here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0aa36c217d4e7ef059b04319547df80f","permalink":"/reading/09-controls/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/09-controls/","section":"reading","summary":"Recommended Slides Tuesday Thursday Recommended None\nSlides Tuesday Class slides here\nThursday Class slides here","tags":null,"title":"Natural Experiments","type":"docs"},{"authors":null,"categories":null,"content":"Instructions Download this: ps-predict right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2e23f502a4a195e5ad5d11c61efcc078","permalink":"/assignment/ps-predict/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/ps-predict/","section":"assignment","summary":"Instructions Download this: ps-predict right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","tags":null,"title":"Prediction","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Predictions (simple model, one explanatory variable) More complicated models (multiple explanatory variables) Interpreting regression output In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù\nday1-prediction.R Predictions (simple model, one explanatory variable) # libraries library(tidyverse) library(broom) library(moderndive) Let‚Äôs say we want to use mtcars to make predictions about a car‚Äôs fuel efficency (mpg) using a car‚Äôs weight (wt).\n# data head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 First we fit a model and look at the output.\n# fitting a model of mpg ~ weight mod = lm(mpg ~ wt, data = mtcars) tidy(mod) ## # A tibble: 2 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 37.3 1.88 19.9 8.24e-19 ## 2 wt -5.34 0.559 -9.56 1.29e-10 Next, we define a scenario we want a prediction for. For example, what MPG should we expect with a car that weighs 1.05 tons?\nscenario = crossing(wt = 1.05) Finally, we use the augment function to get our prediction. We give it our model and our scenario.\n# get my prediction with augment() augment(mod, newdata = scenario) ## # A tibble: 1 √ó 2 ## wt .fitted ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1.05 31.7 We can also do this by hand (plus or minus some rounding!). We just take our regression equation and plug in 1.05 for weight:\n37.3 + -5.34*1.05 ## [1] 31.693 We can make more complicated predictions. For example, predicted MPG for cars with weights 1 through 5:\n# what is the predicted mpg, for a car with: # wt = 1, 2, 3, 4, 5 tons? scenario = crossing(wt = c(1, 2, 3, 4, 5)) # get prediction (i saved as data object to plot below) preds_wt = augment(mod, newdata = scenario) # look at predictions preds_wt ## # A tibble: 5 √ó 2 ## wt .fitted ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 31.9 ## 2 2 26.6 ## 3 3 21.3 ## 4 4 15.9 ## 5 5 10.6 We could use this to plot our predictions:\nggplot(preds_wt, aes(x = wt, y = .fitted)) + # the stuff in geom_col is just for aesthetic purposes! geom_col(color = \u0026quot;white\u0026quot;, fill = \u0026quot;red\u0026quot;, alpha = .8) + theme_light() + labs(x = \u0026quot;Weight (in tons)\u0026quot;, y = \u0026quot;Predicted fuel efficiency\u0026quot;) More complicated models (multiple explanatory variables) The real power of modeling is in using more than one explanatory variable. Below, we can model MPG using car weight (wt), number of cylinders (cyl), horsepower (hp), and the shape of the engine (vs; vs = 0 is v-shaped, vs = 1 is straight).\nmod = lm(mpg ~ wt + cyl + hp + vs, data = mtcars) tidy(mod) ## # A tibble: 5 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 38.5 3.34 11.5 6.14e-12 ## 2 wt -3.18 0.774 -4.11 3.26e- 4 ## 3 cyl -0.905 0.679 -1.33 1.94e- 1 ## 4 hp -0.0179 0.0122 -1.46 1.56e- 1 ## 5 vs 0.155 1.62 0.0957 9.24e- 1 We can then make use of these explanatory variables to make (hopefully) more precise predictions about the outcome we care about. Here‚Äôs an example predicting fuel efficiency for a 1 ton car, with a 4 cylinder engine, with 120 horsepower, and a straight engine:\n# set scenario scen = crossing(wt = 3, cyl = 4, hp = 160, vs = 0) # get prediction augment(mod, newdata = scen) ## # A tibble: 1 √ó 5 ## wt cyl hp vs .fitted ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 3 4 160 0 22.5 I can also get predictions where I vary the values one variable takes on and leave the others at a constant value:\n# i have a car that weighs 1 ton, hp = 100, vs = 0, # what does fuel efficiency look like, if I have 4, 6, 8? scenario = crossing(wt = 1, hp = 100, vs = 0, cyl = c(4, 6, 8)) augment(mod, newdata = scenario) ## # A tibble: 3 √ó 5 ## wt hp vs cyl .fitted ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 100 0 4 29.9 ## 2 1 100 0 6 28.1 ## 3 1 100 0 8 26.3 Interpreting regression output Remember, the basic template for interpreting regression coefficients for continuous variables is the following:\nFor every unit increase in EXPLANATORY VARIABLE there is an associated COEFFICIENT ESTIMATE change in OUTCOME VARIABLE\nThe basic template for interpreting regression coefficients for categorical variables is the following:\nobservations with CATEGORY have, on average, COEFFICIENT ESTIMATE more/less OUTCOME VARIABLE than observations with BASELINE CATEGORY\nAnd the template for interpreting the intercept is the following:\nThe average value of the OUTCOME VARIABLE when all EXPLANATORY VARIABLES are set to 0\nSo with our model above:\ntidy(mod) ## # A tibble: 5 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 38.5 3.34 11.5 6.14e-12 ## 2 wt -3.18 0.774 -4.11 3.26e- 4 ## 3 cyl -0.905 0.679 -1.33 1.94e- 1 ## 4 hp -0.0179 0.0122 -1.46 1.56e- 1 ## 5 vs 0.155 1.62 0.0957 9.24e- 1 wt = for every ADDITIONAL TON OF WEIGHT a car has, there is an associated 3.18 decrease in expected MILES PER GALLON (continuous) cyl = for every ADDITIONAL ENGINE CYLYNDER a car has, there is an associated .905 decrease in expected MILES PER GALLON (continuous) hp = for every ADDITIONAL UNIT OF HORSE POWER a car has, there is an associated .018 decrease in expected MILES PER GALLON (continuous) vs = cars with STRAIGHT ENGINES have, on average, .155 more MILES PER GALLON than cars with V-SHAPED ENGINES. (categorical) intercept = The average MILES PER GALLON of a car with 0 weight (wt = 0), 0 cylinders (cyl = 0), 0 horsepower (hp = 0), and a v-shaped engine (vs = 0) is 38.5. Here‚Äôs a different example, using the evals dataset:\n# fit model mod_evals = lm(score ~ age + bty_avg + gender + rank, data = evals) tidy(mod_evals) ## # A tibble: 6 √ó 5 ## term estimate std.error statistic p.value ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) 4.32 0.195 22.1 3.42e-74 ## 2 age -0.00840 0.00314 -2.67 7.78e- 3 ## 3 bty_avg 0.0624 0.0168 3.72 2.22e- 4 ## 4 gendermale 0.209 0.0522 4.01 7.07e- 5 ## 5 ranktenure track -0.226 0.0804 -2.81 5.13e- 3 ## 6 ranktenured -0.153 0.0622 -2.46 1.42e- 2 age = for every ADDITIONAL YEAR OF AGE of a professor, there is an associated .008 decrease in their STUDENT EVALUATION SCORE (continuous) bty_score = for every ADDITIONAL POINT OF of a professor‚Äôs BEAUTY SCORE, there is an associated .008 decrease in their STUDENT EVALUATION SCORE (continuous) gendermale = MALE professors have, on average, .2 more points on their STUDENT EVALUATION SCORE than FEMALE professors (continuous) ranktenure track = TENURE TRACK professors have, on average, .226 fewer points on their STUDENT EVALUATION SCORE than TEACHING (the baseline!) professors (categorical) ranktenured = TENURED professors have, on average, .153 fewer points on their STUDENT EVALUATION SCORE than TEACHING (the baseline!) professors (categorical) intercept = the average STUDENT EVALUATION SCORE for a professor who is 0 years old (age = 0), has a beauty score of 0 (bty_avg = 0), is female (gendermale = 0), is not tenure track (ranktenure track = 0) and not tenured (ranktenured = 0) (i.e., they are ‚Äúteaching track‚Äù, the baseline category) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"23e596cbb9930f7218a8316df7651dc2","permalink":"/class/prediction/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/prediction/","section":"class","summary":"In-class example Predictions (simple model, one explanatory variable) More complicated models (multiple explanatory variables) Interpreting regression output In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù\nday1-prediction.R Predictions (simple model, one explanatory variable) # libraries library(tidyverse) library(broom) library(moderndive) Let‚Äôs say we want to use mtcars to make predictions about a car‚Äôs fuel efficency (mpg) using a car‚Äôs weight (wt).","tags":null,"title":"Prediction","type":"docs"},{"authors":null,"categories":null,"content":" Recommended Slides Recommended CH.6 in ModernDive, but ignore the stuff on the interactions Slides Class slides here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e885cef24de344aa6a829962ab19811a","permalink":"/reading/06-pred/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/06-pred/","section":"reading","summary":"Recommended Slides Recommended CH.6 in ModernDive, but ignore the stuff on the interactions Slides Class slides here","tags":null,"title":"Prediction","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Example: UN voting patterns In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nUN Voting Data\nExample: UN voting patterns Your first class script eat-cake.R does two things:\ntakes a dataset that records every vote at the UN going back decades and cleans it visualizes voting patterns over time for the US and Turkey At this point, none of this should ‚Äúmake sense‚Äù to you. You do not need to understand what each line of code here does. I just want you to run the code and try to make sense of what the different parts are doing.\nLet‚Äôs break the script down:\nThe first thing the script does is load a set of packages, or libraries, which will give us access to the UN data and functions to use with that data.\nlibrary(tidyverse) library(unvotes) # this is where the UN data lives library(lubridate) library(scales) We can see some of the UN data below:\nun_votes %\u0026gt;% slice(1:5) %\u0026gt;% knitr::kable() rcid country country_code vote 3 United States US yes 3 Canada CA no 3 Cuba CU yes 3 Haiti HT yes 3 Dominican Republic DO yes The variable rcid is the way the data identifies the issue being voted on. So on RCID 3, the US voted ‚Äúyes‚Äù while Canada voted ‚Äúno‚Äù.\nHere are some of the issues:\nun_roll_calls %\u0026gt;% select(rcid, date, short) %\u0026gt;% slice(1:5) %\u0026gt;% knitr::kable() rcid date short 3 1946-01-01 AMENDMENTS, RULES OF PROCEDURE 4 1946-01-02 SECURITY COUNCIL ELECTIONS 5 1946-01-04 VOTING PROCEDURE 6 1946-01-04 DECLARATION OF HUMAN RIGHTS 7 1946-01-02 GENERAL ASSEMBLY ELECTIONS The next chunk of code takes the UN voting data and calculates the percentage of times the US and Turkey voted ‚Äúyes‚Äù on an issue in each year for which there is data.\nun_yes = un_votes %\u0026gt;% filter(country %in% c(\u0026quot;United States\u0026quot;, \u0026quot;Turkey\u0026quot;)) %\u0026gt;% inner_join(un_roll_calls, by = \u0026quot;rcid\u0026quot;) %\u0026gt;% inner_join(un_roll_call_issues, by = \u0026quot;rcid\u0026quot;) %\u0026gt;% group_by(country, year = year(date), issue) %\u0026gt;% summarize( votes = n(), percent_yes = mean(vote == \u0026quot;yes\u0026quot;) ) %\u0026gt;% filter(votes \u0026gt; 5) # only use records where there are more than 5 votes You can see the results of this below:\nun_yes %\u0026gt;% head() %\u0026gt;% knitr::kable() country year issue votes percent_yes Turkey 1946 Colonialism 15 0.8000000 Turkey 1946 Economic development 10 0.6000000 Turkey 1947 Colonialism 9 0.2222222 Turkey 1947 Palestinian conflict 7 0.1428571 Turkey 1948 Colonialism 12 0.4166667 Turkey 1948 Arms control and disarmament 9 0.0000000 So in 1946 Turkey voted 15 times on issues related to ‚ÄúColonialism‚Äù, and of those votes, 80% were a ‚Äúyes‚Äù.\nThis last bit of code produces the visualization:\nggplot(un_yes, aes(x = year, y = percent_yes, color = country)) + geom_point() + geom_smooth(method = \u0026quot;loess\u0026quot;, se = FALSE) + facet_wrap(~ issue) + labs( title = \u0026quot;Percentage of \u0026#39;Yes\u0026#39; votes in the UN General Assembly\u0026quot;, subtitle = \u0026quot;1946 to 2015\u0026quot;, y = \u0026quot;% Yes\u0026quot;, x = \u0026quot;Year\u0026quot;, color = \u0026quot;Country\u0026quot; ) + scale_y_continuous(labels = percent) Try playing around with the code! What happens when you replace the United States and/or Turkey with another country?\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e6245a1009ba731a284f382a6d3e26f6","permalink":"/class/getting-started/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/getting-started/","section":"class","summary":"In-class example Example: UN voting patterns In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nUN Voting Data\nExample: UN voting patterns Your first class script eat-cake.R does two things:\ntakes a dataset that records every vote at the UN going back decades and cleans it visualizes voting patterns over time for the US and Turkey At this point, none of this should ‚Äúmake sense‚Äù to you.","tags":null,"title":"R, Rstudio, basics","type":"docs"},{"authors":null,"categories":null,"content":" Required Slides Required If you haven‚Äôt already done so, go to this Google Form and tell me about yourself Read the syllabus and assignments pages for this class You need to install R and Rstudio following this guide Slides Slides would go here, but there are none on the first week of class.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d6132e5ff202b9b5661a2eb7f64c2399","permalink":"/reading/01-start/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/01-start/","section":"reading","summary":"Required Slides Required If you haven‚Äôt already done so, go to this Google Form and tell me about yourself Read the syllabus and assignments pages for this class You need to install R and Rstudio following this guide Slides Slides would go here, but there are none on the first week of class.","tags":null,"title":"R, Rstudio, basics","type":"docs"},{"authors":null,"categories":null,"content":" Regression discontinuity design (RDD) Regression discontinuity design (RDD) Remember the example from class about the effect of being in a gifted program on future earnings. The DAG looks like this:\nlibrary(ggdag) library(tidyverse) # dag dagify(earnings ~ gifted + ability, gifted ~ ability, exposure = \u0026quot;gifted\u0026quot;, outcome = \u0026quot;earnings\u0026quot;) %\u0026gt;% ggdag_status(text = FALSE, use_labels = \u0026quot;name\u0026quot;) + theme_dag() + theme(legend.position = \u0026quot;none\u0026quot;) The problem is that students aren‚Äôt randomly placed in gifted programs; they are put there for a host of reasons (including, for instance, ‚Äúability‚Äù).\nThe idea behind the RDD is to exploit the fact that the exact test score that gets you into gifted is arbitrary, while the test itself is noisy. This means that students just below and above that cutoff score (75) are pretty similar, but some just barely made it and others just barely didn‚Äôt (for reasons that are arguably random: luck, mostly).\nThat phrase is key: ‚Äúfor reasons that are arguably random‚Ä¶‚Äù. Some students got treatment and others got the control condition randomly, i.e., an experiment.\nMake up data to see how it works:\nset.seed(1991) # discontinuity example fake = tibble(kids = 1:1000, test = runif(1000)*100) %\u0026gt;% mutate(gifted = ifelse(test \u0026gt;= 75, 1, 0)) %\u0026gt;% mutate(earnings = runif(1000)*40 + 10*gifted + .5*test) ggplot(fake, aes(x = test, y = earnings)) + geom_point() Do it by hand:\n# rdd by hand fake %\u0026gt;% filter(test \u0026gt;= 73, test \u0026lt;= 77) %\u0026gt;% group_by(gifted) %\u0026gt;% summarise(earnings = mean(earnings)) ## # A tibble: 2 x 2 ## gifted earnings ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 54.7 ## 2 1 68.2 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"77a26ff7af398a7918c56ae9027dc940","permalink":"/class/rdd/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/rdd/","section":"class","summary":"Regression discontinuity design (RDD) Regression discontinuity design (RDD) Remember the example from class about the effect of being in a gifted program on future earnings. The DAG looks like this:\nlibrary(ggdag) library(tidyverse) # dag dagify(earnings ~ gifted + ability, gifted ~ ability, exposure = \u0026quot;gifted\u0026quot;, outcome = \u0026quot;earnings\u0026quot;) %\u0026gt;% ggdag_status(text = FALSE, use_labels = \u0026quot;name\u0026quot;) + theme_dag() + theme(legend.position = \u0026quot;none\u0026quot;) The problem is that students aren‚Äôt randomly placed in gifted programs; they are put there for a host of reasons (including, for instance, ‚Äúability‚Äù).","tags":null,"title":"Regression discontinuity","type":"docs"},{"authors":null,"categories":null,"content":" Required Required Watch this very short video from this weird, EU robot-voice example ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"577dd5b8bb2d00c46c6309f40f368219","permalink":"/reading/reg-discon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/reg-discon/","section":"reading","summary":" Required Required Watch this very short video from this weird, EU robot-voice example ","tags":null,"title":"Regression discontinuity","type":"docs"},{"authors":null,"categories":null,"content":" Every weekly session has three sections.\nRead: This page contains the slides and optional reading for the week. HW: This page contains any problem sets for the week. Try: This page contains example code from each week‚Äôs content. Data wrangling Read HW Code Sep 22 Week 1: Introduction Sep 27, Sep 29 Week 2: Visualizing data with ggplot\nAssignment 1 Oct 4, Oct 6 Week 3: Data wrangling\nAssignment 2 Relationships in data Read HW Code Oct 11, Oct 13 Week 4: Relationships between variables\nAssignment 3 Oct 18, Oct 20 Week 5: Modeling\nAssignment 4 Oct 25, Oct 27 Week 6: Prediction\nAssignment 5 Causality Read HW Code Nov 1, Nov 3 Week 7: Causality and confounds Nov 8, Nov 10 Week 8: DAGs and controls\nAssignment 6 Nov 15, Nov 17 Week 9: Natural experiments\nCancelled: Assignment 7 Uncertainty Read HW Code Nov 22 Week 10: Uncertainty (no class Thursday: Thanksgiving) Nov 29 - Dec 1 Week 11: Quantifying uncertainty\nAssignment 8 Dec 7th, 11:59PM Final Project Due ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Every weekly session has three sections.\nRead: This page contains the slides and optional reading for the week. HW: This page contains any problem sets for the week. Try: This page contains example code from each week‚Äôs content. Data wrangling Read HW Code Sep 22 Week 1: Introduction Sep 27, Sep 29 Week 2: Visualizing data with ggplot\nAssignment 1 Oct 4, Oct 6 Week 3: Data wrangling\nAssignment 2 Relationships in data Read HW Code Oct 11, Oct 13 Week 4: Relationships between variables","tags":null,"title":"Schedule","type":"page"},{"authors":null,"categories":null,"content":" Recommended Recommended Slides Tuesday Thursday Recommended Ch. 3 in ModernDive Ch. 5 in R for Data Science Recommended Print out this cheat sheet and have it somewhere handy while you‚Äôre doing work in this course Slides Tuesday Class slides here\nThursday Class slides here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"59d9950197000b50ba899125e2b1c353","permalink":"/reading/04-relationships/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/04-relationships/","section":"reading","summary":"Recommended Recommended Slides Tuesday Thursday Recommended Ch. 3 in ModernDive Ch. 5 in R for Data Science Recommended Print out this cheat sheet and have it somewhere handy while you‚Äôre doing work in this course Slides Tuesday Class slides here\nThursday Class slides here","tags":null,"title":"Summarizing data","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Summarize Summarize + group_by() The Bob Ross example The flying etiquette example In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù\nday1-summarise.R day2-summarise.R Summarize Let‚Äôs load the libraries.\n# libraries library(tidyverse) library(nycflights13) library(fivethirtyeight) Say we want to take the average of a variable in our dataset. summarize() can help us do that.\nSay we wanted to know how late in departure is the average flight in our dataset and what‚Äôs the latest a flight has ever been?\n## on average, how late are flights in departing? flights %\u0026gt;% summarise(avg_late = mean(dep_delay, na.rm = TRUE), most_late = max(dep_delay, na.rm = TRUE)) ## # A tibble: 1 √ó 2 ## avg_late most_late ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 12.6 1301 Not the na.rm = TRUE above and what happens if you remove it. The problem is there are missing values (NA) in our data, and R can‚Äôt take the average of a bunch of numbers where some are missing. na.rm = TRUE tells R to ignore those missing numbers and use only the complete observations.\nSummarize + group_by() Say we wanted to know how average departure delays vary across airlines. Conceptually, this means taking the average of departure delays for each airline in the dataset separately. We can do this by combining group_by() and summarise().\n# what if we wanted to know these statistics ## for each month in our dataset? carrier_late = flights %\u0026gt;% group_by(carrier) %\u0026gt;% summarise(avg_late = mean(dep_delay, na.rm = TRUE), most_late = max(dep_delay, na.rm = TRUE)) # make a plot ggplot(carrier_late, aes(x = carrier, y = avg_late)) + geom_col() + coord_flip() The Bob Ross example Happy tree?\nbob_ross %\u0026gt;% summarise(prop_tree = mean(tree, na.rm = TRUE)) ## # A tibble: 1 √ó 1 ## prop_tree ## \u0026lt;dbl\u0026gt; ## 1 0.896 Clouds over time?\nbob_clouds = bob_ross %\u0026gt;% group_by(season) %\u0026gt;% summarise(prop_clouds = mean(clouds, na.rm = TRUE)) ggplot(bob_clouds, aes(x = season, y = prop_clouds)) + geom_line() snowy mountain?\nbob_ross %\u0026gt;% filter(mountain == 1) %\u0026gt;% summarise(snowiness = mean(snowy_mountain, na.rm = TRUE)) ## # A tibble: 1 √ó 1 ## snowiness ## \u0026lt;dbl\u0026gt; ## 1 0.681 bob_ross %\u0026gt;% group_by(mountain) %\u0026gt;% summarise(snowiness = mean(snowy_mountain, na.rm = TRUE)) ## # A tibble: 2 √ó 2 ## mountain snowiness ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 0 ## 2 1 0.681 Steve ross?\nbob_ross %\u0026gt;% group_by(steve_ross) %\u0026gt;% summarise(lake_chance = mean(lake, na.rm = TRUE)) ## # A tibble: 2 √ó 2 ## steve_ross lake_chance ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 0.339 ## 2 1 0.909 The flying etiquette example Middle arm rest?\nmiddle_arm_rests = flying %\u0026gt;% group_by(two_arm_rests) %\u0026gt;% tally() %\u0026gt;% mutate(percent = n/sum(n)) ggplot(middle_arm_rests, aes(x = percent, y = two_arm_rests)) + geom_col() Unruly children?\nnasty_kids = flying %\u0026gt;% group_by(children_under_18, unruly_child) %\u0026gt;% tally() %\u0026gt;% mutate(p_unruly = n/sum(n)) ggplot(nasty_kids, aes(x = unruly_child, y = p_unruly, fill = children_under_18)) + geom_col(position = \u0026quot;dodge\u0026quot;) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1b71de8a8c8577b0259ec1520baafae9","permalink":"/class/data-summary/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/data-summary/","section":"class","summary":"In-class example Summarize Summarize + group_by() The Bob Ross example The flying etiquette example In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù\nday1-summarise.R day2-summarise.R Summarize Let‚Äôs load the libraries.\n# libraries library(tidyverse) library(nycflights13) library(fivethirtyeight) Say we want to take the average of a variable in our dataset.","tags":null,"title":"Summarizing Data","type":"docs"},{"authors":null,"categories":null,"content":" What is this class about? What will we do in this class? What will we do in discussion section? What materials do I need for this course? Course Policies How can I get help or get in contact with the instructors? Honor Code Counseling \u0026amp; Psychiatry Services Assignments and grades Old tech Credits Instructor Howard Liu GAM 219 howard.liu@sc.edu Meet with Prof. Liu Teaching Assistants Matt Fryman MFRYMAN@email.sc.edu OH: TBD Course details T,TH August - Dec, 2023 2:50 PM - 4:00 PM GAM 502 Contacting us E-mail and Slack are the best ways to get in contact with your instructors. We will try to respond to all course-related e-mails and Slack messages quickly, but also remember that life can be busy and chaotic for everyone (including me!)\nWhat is this class about? Policymakers, academics, journalists, firms, NGOs and many others use quantitative data every day to make decisions. Data are also being used to make causal claims about the world ‚Äì to argue that some policy will improve or worsen our lives.\nThis undergraduate course is about how to do data analysis and how to think causally about the political world. We will cover topics in data science, programming, regression, causal inference, and uncertainty.\nThis course assumes students have no statistics or programming background. We will emphasize hands-on application with software and intuition-building instead of statistical theory and mathematical proofs.\nWhat will we do in this class? Our class philosophy is all about doing. Readings are optional ‚Äì everything you need to succeed in class is covered in lecture and section. There are also no exams.\nInstead, you will spend time getting your hands dirty with data in weekly problem sets touching on the class content. You will also complete an original data analysis project on a topic of your choosing that you will showcase at the end of the quarter.\nYou will do this all in R, a powerful and in-demand programming language that will allow you to manipulate, summarize, and visualize the data that you care about. You will also develop a conceptual language for determining whether, and how, we can know that one thing causes another using data.\nBy the end of this course, you will be able to:\nFeel comfortable manipulating data in R Craft effective visualizations of patterns in data Draw causal diagrams and identify obstacles to causal claims Understand the basics of regression and uncertainty What will we do in discussion section? The weekly discussion sections will be the place to get help on lecture content, problem sets, and the final project. In section, you will:\nGo over student questions from the week‚Äôs lecture content Get help from the TAs on new problem sets and review answers from past problem sets Get help from the TAs on your final project What materials do I need for this course? All materials for this course are free and online. You will do all of your analysis with the open source (and free) programming language R. You will use RStudio as the main program to access R.\nGiven the focus on programming, you will need consistent access to a laptop or computer for this class.\nCourse Policies How can I get help or get in contact with the instructors? Slack will be our main mode of communication. We have a class Slack channel where anyone in the class can ask questions and anyone can answer. Ask questions about coding (e.g., ‚Äúhow do I summarize multiple variables at once?‚Äù) or class logistics (e.g., ‚ÄúI can‚Äôt find the reading‚Äù) in the class Slack workspace.\nThe TA‚Äôs and I will monitor Slack regularly, and you should all do so as well. You‚Äôll have similar questions as your peers, and you‚Äôll likely be able to answer other peoples‚Äô questions too.\nIf you need one-on-one help you can also reach out to the TAs to schedule a time to meet. The TAs and their office hours are at the top of this page.\nIf you would like to speak with me about something that only pertains to you (e.g., your grades, academic advice), you can sign up for office hours on Calendly. If there‚Äôs a time-sensitive issue you can email me. Everything else goes in the Slack so that others can see and access help.\nHonor Code Be nice. Don‚Äôt cheat. The Code of Academic Conduct is in effect in this class and all others at the University. I will treat violations seriously. If you have doubts, it is your responsibility to ask about the Code‚Äôs application.\nCounseling \u0026amp; Psychiatry Services Life at Davis can be complicated and challenging. You might feel overwhelmed, experience anxiety or depression, or struggle with relationships or family responsibilities. UC Davis Counseling Services provide confidential support for students who are struggling with mental health and emotional challenges. Please do not hesitate to contact them for assistance‚Äîgetting help is a smart and good thing to do.\nAssignments and grades You can find descriptions for all the assignments on the assignments page.\nAssignment Percent Weekly check-in 15% Problem sets (8) 50% Final project 35% Total 100% Grade Range Grade Range A 93‚Äì100% C 73‚Äì76% A‚àí 90‚Äì92% C‚àí 70‚Äì72% B+ 87‚Äì89% D+ 67‚Äì69% B 83‚Äì86% D 63‚Äì66% B‚àí 80‚Äì82% D‚àí 60‚Äì62% C+ 77‚Äì79% F \u0026lt; 60% Old tech Once you have read this entire syllabus and the assignments page, please post a picture or gif of an old computer, something with a cyberpunk aesthetic, or some old technology to the Slack (I‚Äôll round your final grade up to the nearest whole number; you‚Äôve got until September 29th).\nCredits This course draws on code, content, ideas, inspirations and much more from work by Andrew Heiss, Nick C. Huntington-Klein, Kieran Healy, Scott Cunningham, and others who have made their courses publicly available.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"/syllabus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/syllabus/","section":"","summary":"What is this class about? What will we do in this class? What will we do in discussion section? What materials do I need for this course? Course Policies How can I get help or get in contact with the instructors? Honor Code Counseling \u0026amp; Psychiatry Services Assignments and grades Old tech Credits Instructor Howard Liu GAM 219 howard.liu@sc.edu Meet with Prof. Liu Teaching Assistants Matt Fryman MFRYMAN@email.sc.edu OH: TBD Course details T,TH August - Dec, 2023 2:50 PM - 4:00 PM GAM 502 Contacting us E-mail and Slack are the best ways to get in contact with your instructors.","tags":null,"title":"Syllabus","type":"page"},{"authors":null,"categories":null,"content":" Tidy data Counts and percentages (group_by + tally) Factor variables fct_reorder Tidy data We can use the pivot_longer function to make data that is in ‚Äúwide‚Äù format into ‚Äúlong‚Äù format.\nHere‚Äôs an example, using the drinks dataset from fivethirtyheight.\n# load libraries library(tidyverse) library(fivethirtyeight) # too many countries, let\u0026#39;s look at a few # %in% is a new logical operator: returns observations that match one of the strings drinks_subset = drinks %\u0026gt;% filter(country %in% c(\u0026quot;USA\u0026quot;, \u0026quot;China\u0026quot;, \u0026quot;Italy\u0026quot;, \u0026quot;Saudi Arabia\u0026quot;)) # let\u0026#39;s gather the three alcohol variables into two: type and serving tidy_drinks = drinks_subset %\u0026gt;% pivot_longer(cols = c(beer_servings, spirit_servings, wine_servings), names_to = \u0026quot;type\u0026quot;, values_to = \u0026quot;serving\u0026quot;) tidy_drinks ## # A tibble: 12 x 4 ## country total_litres_of_pure_alcohol type serving ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 China 5 beer_servings 79 ## 2 China 5 spirit_servings 192 ## 3 China 5 wine_servings 8 ## 4 Italy 6.5 beer_servings 85 ## 5 Italy 6.5 spirit_servings 42 ## 6 Italy 6.5 wine_servings 237 ## 7 Saudi Arabia 0.1 beer_servings 0 ## 8 Saudi Arabia 0.1 spirit_servings 5 ## 9 Saudi Arabia 0.1 wine_servings 0 ## 10 USA 8.7 beer_servings 249 ## 11 USA 8.7 spirit_servings 158 ## 12 USA 8.7 wine_servings 84 # let\u0026#39;s put position = dodge in geom_col, which will place bars side by side ggplot(tidy_drinks, aes(x = country, y = serving, fill = type)) + geom_col(position = \u0026quot;dodge\u0026quot;) Here‚Äôs another example, using the masculinity survey from fivethirtyeight.\n# different dataset on masculinity masculinity_survey ## # A tibble: 189 x 12 ## question response overall age_18_34 age_35_64 age_65_over white_yes white_no ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 \u0026quot;In gen‚Ä¶ Very ma‚Ä¶ 0.37 0.290 0.42 0.37 0.34 0.44 ## 2 \u0026quot;In gen‚Ä¶ Somewha‚Ä¶ 0.46 0.47 0.46 0.47 0.5 0.39 ## 3 \u0026quot;In gen‚Ä¶ Not ver‚Ä¶ 0.11 0.13 0.09 0.13 0.11 0.11 ## 4 \u0026quot;In gen‚Ä¶ Not at ‚Ä¶ 0.05 0.1 0.02 0.03 0.04 0.06 ## 5 \u0026quot;In gen‚Ä¶ No answ‚Ä¶ 0.01 0 0.01 0.01 0.01 0 ## 6 \u0026quot;How im‚Ä¶ Very im‚Ä¶ 0.16 0.18 0.17 0.13 0.11 0.26 ## 7 \u0026quot;How im‚Ä¶ Somewha‚Ä¶ 0.37 0.38 0.37 0.32 0.38 0.35 ## 8 \u0026quot;How im‚Ä¶ Not too‚Ä¶ 0.28 0.18 0.31 0.37 0.32 0.2 ## 9 \u0026quot;How im‚Ä¶ Not at ‚Ä¶ 0.18 0.26 0.15 0.18 0.18 0.19 ## 10 \u0026quot;How im‚Ä¶ No answ‚Ä¶ 0 0 0.01 0 0 0 ## # ‚Ä¶ with 179 more rows, and 4 more variables: children_yes \u0026lt;dbl\u0026gt;, ## # children_no \u0026lt;dbl\u0026gt;, straight_yes \u0026lt;dbl\u0026gt;, straight_no \u0026lt;dbl\u0026gt; # focus on one question # collapse age categories into long format manly_pressure = masculinity_survey %\u0026gt;% filter(question == \u0026quot;Do you think that society puts pressure on men in a way that is unhealthy or bad for them?\u0026quot;) %\u0026gt;% pivot_longer(names_to = \u0026quot;ages\u0026quot;, values_to = \u0026quot;percent\u0026quot;, c(age_18_34, age_35_64, age_65_over)) manly_pressure ## # A tibble: 9 x 11 ## question response overall white_yes white_no children_yes children_no ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Do you ‚Ä¶ Yes 0.6 0.580 0.65 0.56 0.66 ## 2 Do you ‚Ä¶ Yes 0.6 0.580 0.65 0.56 0.66 ## 3 Do you ‚Ä¶ Yes 0.6 0.580 0.65 0.56 0.66 ## 4 Do you ‚Ä¶ No 0.39 0.41 0.35 0.44 0.34 ## 5 Do you ‚Ä¶ No 0.39 0.41 0.35 0.44 0.34 ## 6 Do you ‚Ä¶ No 0.39 0.41 0.35 0.44 0.34 ## 7 Do you ‚Ä¶ No answ‚Ä¶ 0.01 0.01 0 0.01 0 ## 8 Do you ‚Ä¶ No answ‚Ä¶ 0.01 0.01 0 0.01 0 ## 9 Do you ‚Ä¶ No answ‚Ä¶ 0.01 0.01 0 0.01 0 ## # ‚Ä¶ with 4 more variables: straight_yes \u0026lt;dbl\u0026gt;, straight_no \u0026lt;dbl\u0026gt;, ages \u0026lt;chr\u0026gt;, ## # percent \u0026lt;dbl\u0026gt; And we can plot the results:\n# plot ggplot(manly_pressure, aes(x = response, y = percent, fill = ages)) + geom_col(position = \u0026quot;dodge\u0026quot;) Finally, here‚Äôs another example using relig_income. Notice here how instead of explicitly writing out every variable we want to collapse, we can just exclude the only other variable in the dataset via the ‚Äú-‚Äù.\n# look at the data relig_income ## # A tibble: 18 x 11 ## religion `\u0026lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k` ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Agnostic 27 34 60 81 76 137 122 ## 2 Atheist 12 27 37 52 35 70 73 ## 3 Buddhist 27 21 30 34 33 58 62 ## 4 Catholic 418 617 732 670 638 1116 949 ## 5 Don‚Äôt k‚Ä¶ 15 14 15 11 10 35 21 ## 6 Evangel‚Ä¶ 575 869 1064 982 881 1486 949 ## 7 Hindu 1 9 7 9 11 34 47 ## 8 Histori‚Ä¶ 228 244 236 238 197 223 131 ## 9 Jehovah‚Ä¶ 20 27 24 24 21 30 15 ## 10 Jewish 19 19 25 25 30 95 69 ## 11 Mainlin‚Ä¶ 289 495 619 655 651 1107 939 ## 12 Mormon 29 40 48 51 56 112 85 ## 13 Muslim 6 7 9 10 9 23 16 ## 14 Orthodox 13 17 23 32 32 47 38 ## 15 Other C‚Ä¶ 9 7 11 13 13 14 18 ## 16 Other F‚Ä¶ 20 33 40 46 49 63 46 ## 17 Other W‚Ä¶ 5 2 3 4 2 7 3 ## 18 Unaffil‚Ä¶ 217 299 374 365 341 528 407 ## # ‚Ä¶ with 3 more variables: `$100-150k` \u0026lt;dbl\u0026gt;, `\u0026gt;150k` \u0026lt;dbl\u0026gt;, `Don\u0026#39;t ## # know/refused` \u0026lt;dbl\u0026gt; # make tidy tidy_relig = relig_income %\u0026gt;% pivot_longer(-religion, names_to = \u0026quot;income_categories\u0026quot;, values_to = \u0026quot;responses\u0026quot;) %\u0026gt;% group_by(religion) %\u0026gt;% mutate(percent = responses/sum(responses)) # make the plot ggplot(tidy_relig, aes(x = income_categories, y = percent)) + geom_col() + facet_wrap(vars(religion)) + coord_flip() + theme_light() Counts and percentages (group_by + tally) Say we wanted to count how many characters in the starwars dataset have blonde, brown, etc., hair. I can do this with group_by and tally:\nstarwars %\u0026gt;% group_by(hair_color) %\u0026gt;% tally() ## # A tibble: 13 x 2 ## hair_color n ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 auburn 1 ## 2 auburn, grey 1 ## 3 auburn, white 1 ## 4 black 13 ## 5 blond 3 ## 6 blonde 1 ## 7 brown 18 ## 8 brown, grey 1 ## 9 grey 1 ## 10 none 37 ## 11 unknown 1 ## 12 white 4 ## 13 \u0026lt;NA\u0026gt; 5 Or, with group_by and summarise and n():\nstarwars %\u0026gt;% group_by(hair_color) %\u0026gt;% summarise(n = n()) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 13 x 2 ## hair_color n ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 auburn 1 ## 2 auburn, grey 1 ## 3 auburn, white 1 ## 4 black 13 ## 5 blond 3 ## 6 blonde 1 ## 7 brown 18 ## 8 brown, grey 1 ## 9 grey 1 ## 10 none 37 ## 11 unknown 1 ## 12 white 4 ## 13 \u0026lt;NA\u0026gt; 5 Now, say I wanted to calculate the percent of characters with each eye color. I can do this below:\nstarwars %\u0026gt;% group_by(hair_color) %\u0026gt;% tally() %\u0026gt;% mutate(percent = n/sum(n)) ## # A tibble: 13 x 3 ## hair_color n percent ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 auburn 1 0.0115 ## 2 auburn, grey 1 0.0115 ## 3 auburn, white 1 0.0115 ## 4 black 13 0.149 ## 5 blond 3 0.0345 ## 6 blonde 1 0.0115 ## 7 brown 18 0.207 ## 8 brown, grey 1 0.0115 ## 9 grey 1 0.0115 ## 10 none 37 0.425 ## 11 unknown 1 0.0115 ## 12 white 4 0.0460 ## 13 \u0026lt;NA\u0026gt; 5 0.0575 Factor variables Sometimes we have a categorical variable (e.g., months of the year) that we understand as having some qualitative ordering (e.g., January comes before June). R doesn‚Äôt know this though, but we can tell it using factor variables.\nHere‚Äôs an example using some data I made up:\n# i have data on weather that looks like this: weather = tibble(temp = c(80, 23, 14, 23, 25), month = c(\u0026quot;January\u0026quot;, \u0026quot;December\u0026quot;, \u0026quot;July\u0026quot;, \u0026quot;June\u0026quot;, \u0026quot;October\u0026quot;)) weather ## # A tibble: 5 x 2 ## temp month ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 80 January ## 2 23 December ## 3 14 July ## 4 23 June ## 5 25 October # i want the month variable in order # i can use factors for this weather_factor = weather %\u0026gt;% mutate(month_factor = factor(month, levels = c(\u0026quot;January\u0026quot;, \u0026quot;June\u0026quot;, \u0026quot;July\u0026quot;, \u0026quot;October\u0026quot;, \u0026quot;December\u0026quot;))) Notice plot without factor:\nggplot(weather, aes(x = month, y = temp)) + geom_col() And new and imrpoved plot where month is a factor:\nggplot(weather_factor, aes(x = month_factor, y = temp)) + geom_col() fct_reorder Instead of explicitly telling R how we want to order a factor, we can instead use another variable in the dataset to determine the order.\nLook at the example below, using the starwars dataset:\n# starwars example starwars ## # A tibble: 87 x 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Luke‚Ä¶ 172 77 blond fair blue 19 male mascu‚Ä¶ ## 2 C-3PO 167 75 \u0026lt;NA\u0026gt; gold yellow 112 none mascu‚Ä¶ ## 3 R2-D2 96 32 \u0026lt;NA\u0026gt; white, bl‚Ä¶ red 33 none mascu‚Ä¶ ## 4 Dart‚Ä¶ 202 136 none white yellow 41.9 male mascu‚Ä¶ ## 5 Leia‚Ä¶ 150 49 brown light brown 19 fema‚Ä¶ femin‚Ä¶ ## 6 Owen‚Ä¶ 178 120 brown, gr‚Ä¶ light blue 52 male mascu‚Ä¶ ## 7 Beru‚Ä¶ 165 75 brown light blue 47 fema‚Ä¶ femin‚Ä¶ ## 8 R5-D4 97 32 \u0026lt;NA\u0026gt; white, red red NA none mascu‚Ä¶ ## 9 Bigg‚Ä¶ 183 84 black light brown 24 male mascu‚Ä¶ ## 10 Obi-‚Ä¶ 182 77 auburn, w‚Ä¶ fair blue-gray 57 male mascu‚Ä¶ ## # ‚Ä¶ with 77 more rows, and 5 more variables: homeworld \u0026lt;chr\u0026gt;, species \u0026lt;chr\u0026gt;, ## # films \u0026lt;list\u0026gt;, vehicles \u0026lt;list\u0026gt;, starships \u0026lt;list\u0026gt; # count how many characters with each eye_color star_eyes = starwars %\u0026gt;% group_by(eye_color) %\u0026gt;% tally() star_eyes = star_eyes %\u0026gt;% mutate(eye_color = fct_reorder(eye_color, n)) ggplot(star_eyes, aes(x = eye_color, y = n)) + geom_col() + coord_flip() ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"596eaef928cbd53e495cd22d1b771556","permalink":"/class/data-tidy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/data-tidy/","section":"class","summary":"Tidy data Counts and percentages (group_by + tally) Factor variables fct_reorder Tidy data We can use the pivot_longer function to make data that is in ‚Äúwide‚Äù format into ‚Äúlong‚Äù format.\nHere‚Äôs an example, using the drinks dataset from fivethirtyheight.\n# load libraries library(tidyverse) library(fivethirtyeight) # too many countries, let\u0026#39;s look at a few # %in% is a new logical operator: returns observations that match one of the strings drinks_subset = drinks %\u0026gt;% filter(country %in% c(\u0026quot;USA\u0026quot;, \u0026quot;China\u0026quot;, \u0026quot;Italy\u0026quot;, \u0026quot;Saudi Arabia\u0026quot;)) # let\u0026#39;s gather the three alcohol variables into two: type and serving tidy_drinks = drinks_subset %\u0026gt;% pivot_longer(cols = c(beer_servings, spirit_servings, wine_servings), names_to = \u0026quot;type\u0026quot;, values_to = \u0026quot;serving\u0026quot;) tidy_drinks ## # A tibble: 12 x 4 ## country total_litres_of_pure_alcohol type serving ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 China 5 beer_servings 79 ## 2 China 5 spirit_servings 192 ## 3 China 5 wine_servings 8 ## 4 Italy 6.","tags":null,"title":"Tidy data","type":"docs"},{"authors":null,"categories":null,"content":"Instructions Download this: ps-uncertainty right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"567fd951d48c5032df4769ca154d9b69","permalink":"/assignment/ps-uncertainty/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/ps-uncertainty/","section":"assignment","summary":"Instructions Download this: ps-uncertainty right-click, \u0026ldquo;save/download file as\u0026hellip;\u0026rdquo; Complete all of the coding tasks in the .Rmd file Once you are done, go on Canvas and answer the questions related to the assignment You will submit your .Rmd file in the Canvas assignment Tips Make sure you: run all of the code chunks that already have code in them write your code in the empty code chunks Useful shortcuts: to run all the code in a specific code chunk, press the green right-facing triangle at the top right of the code chunk to run all prior code chunks, press the downward-facing gray triangle at the top right of the code chunk ","tags":null,"title":"Uncertainty","type":"docs"},{"authors":null,"categories":null,"content":" In-class example Other examples Why are we uncertain? Become less uncertain More data, more certain Good and bad samples In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nday1-uncertainty.R\nOther examples library(tidyverse) library(broom) library(socviz) library(moderndive) set.seed(1990) Why are we uncertain? Remember that with data we are always trying to estimate something: the effect of X on Y, the average value of Y among some population, etc, ‚Äì but we can be more or less certain about our estimate.\nA key reason we are uncertain is that our data is usually a sample of something bigger that we want to learn about (that bigger thing = the population). The problem is that each sample is going to give us a (slightly) different answer.\nFor example, below, imagine that in the US there were only \\(\\approx\\) 2,800 people, and they were all included in the gss_sm dataset from socviz.\nWhat proportion of men and women voted for Obama in 2012? In this made up example, we can know the exact answer:\ntrue_prop = gss_sm %\u0026gt;% group_by(sex) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) true_prop ## # A tibble: 2 √ó 2 ## sex obama ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Male 0.576 ## 2 Female 0.663 Now, imagine that we instead only had a sample of gss_sm. Say, we picked 10 random people from gss_sm and calculated the proportion of support among men and women for Obama.\ngss_sm %\u0026gt;% # randomly draw 10 observations sample_n(10) %\u0026gt;% group_by(sex) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) ## # A tibble: 2 √ó 2 ## sex obama ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Male 0.25 ## 2 Female 1 Run the code above over and over. Notice: you get a different answer each time! Some very far from the true proportion of men and women who voted from Obama. This is the big problem: we only have a sample and each sample gives us a different answer.1 How do we know that our sample is close to the true answer and not weirdly off?\nBecome less uncertain It turns out that if a sample is random, representative, and large, our estimate from the sample will be pretty close to the estimate from the population.\nLet‚Äôs see how this works: the code below uses the function rep_sample_n from moderndive to:\nPick N random people from gss_sm (our sample) Estimate the proportion of men and women who voted for Obama in that sample (our sample estimate) Repeat this P times Below, N = 10 and P = 10. So 10 different samples, each with 10 random people.\ngss_sm %\u0026gt;% # 10 samples, each of size 10 rep_sample_n(size = 10, reps = 10) %\u0026gt;% group_by(sex, replicate) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) %\u0026gt;% arrange(replicate) ## # A tibble: 19 √ó 3 ## # Groups: sex [2] ## sex replicate obama ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Female 1 0.571 ## 2 Male 2 NaN ## 3 Female 2 0.333 ## 4 Male 3 0 ## 5 Female 3 0.5 ## 6 Male 4 0.5 ## 7 Female 4 0.5 ## 8 Male 5 0 ## 9 Female 5 1 ## 10 Male 6 0.5 ## 11 Female 6 0.6 ## 12 Male 7 0 ## 13 Female 7 1 ## 14 Male 8 0.667 ## 15 Female 8 0.5 ## 16 Male 9 1 ## 17 Female 9 1 ## 18 Male 10 0.5 ## 19 Female 10 0.5 Notice how the sample estimate differ varies across samples (the replicate variable tells you which sample you are looking at).\nLet‚Äôs do this many more times, and plot the distribution of our sample estimates. Below, each sample only has 10 people in it, and we take 1,000 samples. The black bars are the proportion of men and women who voted for Obama across all of gss_sm (the population parameter):\ngss_sm %\u0026gt;% rep_sample_n(size = 10, reps = 1000) %\u0026gt;% group_by(replicate, sex) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) %\u0026gt;% ggplot(aes(x = obama, fill = sex)) + geom_histogram(color = \u0026quot;white\u0026quot;, alpha = .8) + facet_wrap(vars(sex), scales = \u0026quot;free\u0026quot;) + theme_bw() + geom_vline(data = true_prop, aes(xintercept = obama), size = 2, color = \u0026quot;black\u0026quot;) This is a sample that is random and representative, but small (only 10 people in each sample!). Notice how some of our sample estimates are far off from the population estimate: we get lots of cases where every man, for instance, voted for Obama, which is really wrong.\ngss_sm %\u0026gt;% rep_sample_n(size = 10, reps = 1000) %\u0026gt;% group_by(replicate, sex) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) %\u0026gt;% ggplot(aes(x = obama, fill = sex)) + geom_histogram(color = \u0026quot;white\u0026quot;, alpha = .8) + facet_wrap(vars(sex), scales = \u0026quot;free\u0026quot;) + theme_bw() + geom_vline(data = true_prop, aes(xintercept = obama), size = 2, color = \u0026quot;black\u0026quot;) + scale_x_continuous(limits = c(-.1, 1.1)) Now look what happens when we make our samples bigger, for instance, where each sample is composed of 50 people:\ngss_sm %\u0026gt;% rep_sample_n(size = 50, reps = 1000) %\u0026gt;% group_by(replicate, sex) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) %\u0026gt;% ggplot(aes(x = obama, fill = sex)) + geom_histogram(color = \u0026quot;white\u0026quot;, alpha = .8) + facet_wrap(vars(sex), scales = \u0026quot;free\u0026quot;) + theme_bw() + geom_vline(data = true_prop, aes(xintercept = obama), size = 2, color = \u0026quot;black\u0026quot;) + scale_x_continuous(limits = c(0, 1)) + scale_x_continuous(limits = c(-.1, 1.1)) Now our estimates look very different: many of them are pretty close to the true population proportion. Let‚Äôs make our samples even bigger, with 100 people each:\ngss_sm %\u0026gt;% rep_sample_n(size = 100, reps = 1000) %\u0026gt;% group_by(replicate, sex) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) %\u0026gt;% ggplot(aes(x = obama, fill = sex)) + geom_histogram(color = \u0026quot;white\u0026quot;, alpha = .8) + facet_wrap(vars(sex), scales = \u0026quot;free\u0026quot;) + theme_bw() + geom_vline(data = true_prop, aes(xintercept = obama), size = 2, color = \u0026quot;black\u0026quot;) + scale_x_continuous(limits = c(0, 1)) + scale_x_continuous(limits = c(-.1, 1.1)) Notice how much ‚Äúnarrower‚Äù the distribution is getting. We‚Äôre getting fewer and fewer samples that are far away from the black line. Let‚Äôs look at a sample of 500:\ngss_sm %\u0026gt;% rep_sample_n(size = 500, reps = 1000) %\u0026gt;% group_by(replicate, sex) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) %\u0026gt;% ggplot(aes(x = obama, fill = sex)) + geom_histogram(color = \u0026quot;white\u0026quot;, alpha = .8) + facet_wrap(vars(sex), scales = \u0026quot;free\u0026quot;) + theme_bw() + geom_vline(data = true_prop, aes(xintercept = obama), size = 2, color = \u0026quot;black\u0026quot;) + scale_x_continuous(limits = c(0, 1)) + scale_x_continuous(limits = c(-.1, 1.1)) Even closer! The result is that if you take a large, random, representative sample the vast majority of estimates are going to be pretty damn close to the population parameter.\nMore data, more certain What‚Äôs happening above is pretty intuitive; if you are estimating something, you should feel more confident about that estimate the more data you have.\nCompare the two trend-lines below: we should be much more certain about the one on the left, even though both have the sample slope (2)!\n# uncertainty example low_certain = tibble(x = rnorm(10), y = 2*x + rnorm(10), certain = \u0026quot;low\u0026quot;) hi_certain = tibble(x = rnorm(1000), y = 2*x + rnorm(1000), certain = \u0026quot;high\u0026quot;) rbind(low_certain, hi_certain) %\u0026gt;% ggplot(aes(x = x, y = y, color = certain)) + geom_jitter(size = 2, width = 1) + facet_wrap(vars(certain)) + geom_smooth(method = \u0026quot;lm\u0026quot;, color = \u0026quot;blue\u0026quot;) + theme_bw() + theme(legend.position = \u0026quot;none\u0026quot;) Good and bad samples Bigger samples decrease uncertainty in our estimate, but this all hinges on the sample being good. By good I mean the sample is random and representative of the population.\nWhat makes a sample representative of the population? It‚Äôs easier to think about what makes a sample unrepresentative. Imagine, for whatever reason, that in the example above, no one under 50 showed up in our sample.\nWe can simulate this easily by just adding a call to filter below to exclude people below 50:\ngss_sm %\u0026gt;% filter(age \u0026gt;= 50) %\u0026gt;% rep_sample_n(size = 500, reps = 1000) %\u0026gt;% group_by(replicate, sex) %\u0026gt;% summarise(obama = mean(obama, na.rm = TRUE)) %\u0026gt;% ggplot(aes(x = obama, fill = sex)) + geom_histogram(color = \u0026quot;white\u0026quot;, alpha = .8) + facet_wrap(vars(sex), scales = \u0026quot;free\u0026quot;) + theme_bw() + geom_vline(data = true_prop, aes(xintercept = obama), size = 2, color = \u0026quot;black\u0026quot;) + scale_x_continuous(limits = c(0, 1)) + scale_x_continuous(limits = c(-.1, 1.1)) Notice how the distribution of sample estimates are no longer centered around the true population parameter (the black lines). They are centered elsewhere. Increasing the sample size will continue to make the distribution taller and skinnier, but it will not be centered around the black lines.\nThis is because our sample is biased. In the population, there are people of all sorts of ages. But in our sample, it‚Äôs only older people. A bigger sample will not solve this problem.\nWhy would our sample not have young people in it, even though the population does? These sampling biases happens in the real world all the time. Maybe younger people are less willing to answer polls, or to take surveys, or to have landlines, etc., that means they are ‚Äúmissing‚Äù at higher rates from samples.\nThere are other sources of uncertainty (e.g., measurement error) which we will not discuss here.‚Ü©Ô∏é\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0cf27165ba52dae2a1177747b333dabd","permalink":"/class/uncertainty/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/class/uncertainty/","section":"class","summary":"In-class example Other examples Why are we uncertain? Become less uncertain More data, more certain Good and bad samples In-class example Here‚Äôs the code we‚Äôll be using in class. Download it and store it with the rest of your materials for this course. If simply clicking doesn‚Äôt trigger download, you should right-click and select ‚Äúsave link as‚Ä¶‚Äù.\nday1-uncertainty.R\nOther examples library(tidyverse) library(broom) library(socviz) library(moderndive) set.seed(1990) Why are we uncertain? Remember that with data we are always trying to estimate something: the effect of X on Y, the average value of Y among some population, etc, ‚Äì but we can be more or less certain about our estimate.","tags":null,"title":"Uncertainty","type":"docs"},{"authors":null,"categories":null,"content":" Recommended Slides Tuesday Recommended Chapter 7 from ModernDive Slides Tuesday Class slides here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5b320a08c2f5203fbe8172d2d8fc9bc7","permalink":"/reading/10-uncertainty/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/10-uncertainty/","section":"reading","summary":"Recommended Slides Tuesday Recommended Chapter 7 from ModernDive Slides Tuesday Class slides here","tags":null,"title":"Uncertainty","type":"docs"},{"authors":null,"categories":null,"content":" Recommended Helpful! Slides Tuesday Thursday Recommended Ch.2 in ModernDive on Data Visualization\nCh.3 in R for Data Science\nHelpful! The cheatsheet for data visualization with ggplot might be a helpful resource Slides Tip: You can navigate through the slides with ‚Üê and ‚Üí. If you type F you can go full-screen.\nTuesday Class slides here\nThursday Class slides here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e6058e62707de29f7bcf95bc57b2e5ad","permalink":"/reading/02-viz/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/02-viz/","section":"reading","summary":"Recommended Helpful! Slides Tuesday Thursday Recommended Ch.2 in ModernDive on Data Visualization\nCh.3 in R for Data Science\nHelpful! The cheatsheet for data visualization with ggplot might be a helpful resource Slides Tip: You can navigate through the slides with ‚Üê and ‚Üí. If you type F you can go full-screen.\nTuesday Class slides here\nThursday Class slides here","tags":null,"title":"Visualizing data","type":"docs"},{"authors":null,"categories":null,"content":" Recommended Recommended Slides Tuesday Thursday Recommended Ch. 3 in ModernDive Ch. 5 in R for Data Science Recommended Print out this cheat sheet and have it somewhere handy while you‚Äôre doing work in this course Slides Tip: You can navigate through the slides with ‚Üê and ‚Üí. If you type F you can go full-screen.\nTuesday Class slides here\nThursday Class slides here\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"76876ada7bfc14782f0a115083babfae","permalink":"/reading/03-wrangle/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reading/03-wrangle/","section":"reading","summary":"Recommended Recommended Slides Tuesday Thursday Recommended Ch. 3 in ModernDive Ch. 5 in R for Data Science Recommended Print out this cheat sheet and have it somewhere handy while you‚Äôre doing work in this course Slides Tip: You can navigate through the slides with ‚Üê and ‚Üí. If you type F you can go full-screen.\nTuesday Class slides here\nThursday Class slides here","tags":null,"title":"Wrangling data","type":"docs"}]